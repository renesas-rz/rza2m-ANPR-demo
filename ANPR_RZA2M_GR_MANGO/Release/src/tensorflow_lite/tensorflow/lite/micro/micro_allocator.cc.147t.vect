
;; Function virtual TfLiteStatus tflite::MicroAllocator::AllocateVariables(const tflite::SubGraph*, TfLiteEvalTensor*) (_ZN6tflite14MicroAllocator17AllocateVariablesEPKNS_8SubGraphEP16TfLiteEvalTensor, funcdef_no=6659, decl_uid=180576, cgraph_uid=3791, symbol_order=3832)


Analyzing loop at C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:2449
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:2449:18: note: ===== analyze_loop_nest =====
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:2449:18: note: === vect_analyze_loop_form ===
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:2449:18: note: not vectorized: control flow in loop.
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:2449:18: note: bad loop form.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:869:14: note: vectorized 0 loops in function.
virtual TfLiteStatus tflite::MicroAllocator::AllocateVariables(const tflite::SubGraph*, TfLiteEvalTensor*) (struct MicroAllocator * const this, const struct SubGraph * subgraph, struct TfLiteEvalTensor * eval_tensors)
{
  const uint8_t * p;
  const struct Tensor * D.242352;
  static const char __PRETTY_FUNCTION__[246] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = flatbuffers::Offset<tflite::Tensor>; flatbuffers::Vector<T>::return_type = const tflite::Tensor*; flatbuffers::uoffset_t = long unsigned int]";
  unsigned char * p;
  unsigned char * p;
  size_t buffer_size;
  size_t i;
  TfLiteStatus _2;
  TfLiteStatus _3;
  sizetype _10;
  long unsigned int _15;
  unsigned int _17;
  struct TfLiteEvalTensor * _19;
  const TfLiteStatus _21;
  struct SimpleMemoryAllocator * _23;
  int (*__vtbl_ptr_type) () * _24;
  int (*__vtbl_ptr_type) () _25;
  unsigned int buffer_size.45_26;
  uint8_t * _28;
  sizetype _32;
  const uint8_t * _33;
  int _35;
  short unsigned int _36;
  sizetype _38;
  long unsigned int _40;
  const struct Vector * iftmp.41_41;
  const uint8_t[1] * _43;
  long int _44;
  sizetype _45;
  sizetype _46;
  const uint8_t * _47;
  short unsigned int _48;
  int _49;
  short unsigned int _50;
  sizetype _52;
  const void * _53;
  unsigned char _54;
  const uint8_t[1] * pretmp_59;
  const uint8_t * _64;
  long unsigned int _65;
  long unsigned int _67;
  const struct Tensor * _68;
  long unsigned int _83;
  TfLiteStatus _91;
  long int pretmp_92;
  long int prephitmp_93;
  sizetype _94;
  sizetype _96;
  const uint8_t[1] * _98;
  short unsigned int pretmp_100;
  short unsigned int prephitmp_101;
  long int pretmp_104;
  long int prephitmp_105;
  sizetype _106;
  sizetype _107;
  const uint8_t[1] * _108;
  short unsigned int pretmp_109;
  short unsigned int prephitmp_110;

  <bb 2>:
  pretmp_59 = &MEM[(const struct Table *)subgraph_9(D)].data_;
  pretmp_104 = MEM[(const long int *)subgraph_9(D)];
  _106 = (sizetype) pretmp_104;
  _107 = -_106;
  _108 = pretmp_59 + _107;
  pretmp_109 = MEM[(const short unsigned int *)_108];

  <bb 3>:
  # i_1 = PHI <0(2), i_16(14)>
  # prephitmp_105 = PHI <pretmp_104(2), prephitmp_93(14)>
  # prephitmp_110 = PHI <pretmp_109(2), prephitmp_101(14)>
  _35 = (int) prephitmp_110;
  if (_35 > 4)
    goto <bb 4>;
  else
    goto <bb 16>;

  <bb 4>:
  _10 = (sizetype) prephitmp_105;
  _32 = -_10;
  _33 = pretmp_59 + _32;
  _36 = MEM[(const short unsigned int *)_33 + 4B];
  _38 = (sizetype) _36;
  p_39 = pretmp_59 + _38;
  if (_36 != 0)
    goto <bb 5>;
  else
    goto <bb 16>;

  <bb 5>:
  _40 = MEM[(const long unsigned int *)p_39];
  iftmp.41_41 = p_39 + _40;
  _15 = iftmp.41_41->length_;
  if (i_1 < _15)
    goto <bb 6>;
  else
    goto <bb 15>;

  <bb 6>:
  _64 = &MEM[(void *)iftmp.41_41 + 4B];
  _65 = i_1 * 4;
  p_66 = _64 + _65;
  _67 = MEM[(const long unsigned int *)p_66];
  _68 = p_66 + _67;
  _43 = &MEM[(const struct Table *)_68].data_;
  _44 = MEM[(const long int *)_68];
  _45 = (sizetype) _44;
  _46 = -_45;
  _47 = _43 + _46;
  _48 = MEM[(const short unsigned int *)_47];
  _49 = (int) _48;
  if (_49 > 14)
    goto <bb 7>;
  else
    goto <bb 14>;

  <bb 7>:
  _50 = MEM[(const short unsigned int *)_47 + 14B];
  if (_50 != 0)
    goto <bb 8>;
  else
    goto <bb 14>;

  <bb 8>:
  _52 = (sizetype) _50;
  _53 = _43 + _52;
  _54 = MEM[(const unsigned char *)_53];
  if (_54 != 0)
    goto <bb 9>;
  else
    goto <bb 14>;

  <bb 9>:
  _17 = i_1 * 12;
  _19 = eval_tensors_18(D) + _17;
  _21 = tflite::TfLiteEvalTensorByteLength (_19, &buffer_size);
  if (_21 != 0)
    goto <bb 12>;
  else
    goto <bb 10>;

  <bb 10>:
  _23 = this_22(D)->memory_allocator_;
  _24 = _23->_vptr.SimpleMemoryAllocator;
  _25 = MEM[(int (*__vtbl_ptr_type) () *)_24 + 12B];
  buffer_size.45_26 = buffer_size;
  _28 = OBJ_TYPE_REF(_25;(struct SimpleMemoryAllocator)_23->3) (_23, buffer_size.45_26, 16);
  _19->data.data = _28;
  if (_28 == 0B)
    goto <bb 13>;
  else
    goto <bb 11>;

  <bb 11>:
  buffer_size ={v} {CLOBBER};
  pretmp_92 = MEM[(const long int *)subgraph_9(D)];
  _94 = (sizetype) pretmp_92;
  _96 = -_94;
  _98 = pretmp_59 + _96;
  pretmp_100 = MEM[(const short unsigned int *)_98];
  goto <bb 14>;

  <bb 12>:
  # _91 = PHI <_21(9)>

  <bb 13>:
  # _2 = PHI <_91(12), 1(10)>
  buffer_size ={v} {CLOBBER};
  goto <bb 15>;

  <bb 14>:
  # prephitmp_93 = PHI <prephitmp_105(8), pretmp_92(11), prephitmp_105(6), prephitmp_105(7)>
  # prephitmp_101 = PHI <prephitmp_110(8), pretmp_100(11), prephitmp_110(6), prephitmp_110(7)>
  i_16 = i_1 + 1;
  goto <bb 3>;

  <bb 15>:
  # _3 = PHI <_2(13), 0(5)>
  return _3;

  <bb 16>:
  _83 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

}



;; Function virtual TfLiteStatus tflite::MicroAllocator::AllocateNodeAndRegistrations(const tflite::Model*, tflite::SubgraphAllocations*) (_ZN6tflite14MicroAllocator28AllocateNodeAndRegistrationsEPKNS_5ModelEPNS_19SubgraphAllocationsE, funcdef_no=6654, decl_uid=180568, cgraph_uid=3786, symbol_order=3827)


Analyzing loop at C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: ===== analyze_loop_nest =====
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: === vect_analyze_loop_form ===
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: not vectorized: control flow in loop.
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: bad loop form.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:736:14: note: vectorized 0 loops in function.
virtual TfLiteStatus tflite::MicroAllocator::AllocateNodeAndRegistrations(const tflite::Model*, tflite::SubgraphAllocations*) (struct MicroAllocator * const this, const struct Model * model, struct SubgraphAllocations * subgraph_allocations)
{
  const uint8_t * p;
  const struct SubGraph * D.242365;
  static const char __PRETTY_FUNCTION__[250] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = flatbuffers::Offset<tflite::SubGraph>; flatbuffers::Vector<T>::return_type = const tflite::SubGraph*; flatbuffers::uoffset_t = long unsigned int]";
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  size_t subgraph_idx;
  TfLiteStatus _2;
  sizetype _8;
  sizetype _9;
  long int _10;
  struct SimpleMemoryAllocator * _14;
  int (*__vtbl_ptr_type) () * _15;
  int (*__vtbl_ptr_type) () _16;
  long unsigned int _18;
  long unsigned int _19;
  struct NodeAndRegistration * _21;
  unsigned int _22;
  struct SubgraphAllocations * _23;
  const uint8_t * _28;
  short unsigned int _29;
  int _30;
  short unsigned int _31;
  sizetype _33;
  long unsigned int _35;
  const struct Vector * iftmp.27_36;
  long unsigned int _46;
  const uint8_t[1] * _47;
  long int _48;
  sizetype _49;
  sizetype _50;
  const uint8_t * _51;
  short unsigned int _52;
  int _53;
  short unsigned int _54;
  sizetype _56;
  long unsigned int _58;
  const struct Vector * iftmp.31_59;
  const uint8_t * _62;
  long unsigned int _63;
  long unsigned int _65;
  const struct SubGraph * _66;
  long unsigned int _67;
  const uint8_t[1] * pretmp_82;
  long unsigned int _84;

  <bb 2>:
  if (subgraph_allocations_5(D) != 0B)
    goto <bb 4>;
  else
    goto <bb 3>;

  <bb 3>:
  abort ();

  <bb 4>:
  pretmp_82 = &MEM[(const struct Table *)model_7(D)].data_;

  <bb 5>:
  # subgraph_idx_1 = PHI <0(4), subgraph_idx_25(12)>
  _10 = MEM[(const long int *)model_7(D)];
  _9 = (sizetype) _10;
  _8 = -_9;
  _28 = pretmp_82 + _8;
  _29 = MEM[(const short unsigned int *)_28];
  _30 = (int) _29;
  if (_30 > 8)
    goto <bb 6>;
  else
    goto <bb 14>;

  <bb 6>:
  _31 = MEM[(const short unsigned int *)_28 + 8B];
  _33 = (sizetype) _31;
  p_34 = pretmp_82 + _33;
  if (_31 != 0)
    goto <bb 7>;
  else
    goto <bb 14>;

  <bb 7>:
  _35 = MEM[(const long unsigned int *)p_34];
  iftmp.27_36 = p_34 + _35;
  _18 = iftmp.27_36->length_;
  if (subgraph_idx_1 < _18)
    goto <bb 8>;
  else
    goto <bb 13>;

  <bb 8>:
  _62 = &MEM[(void *)iftmp.27_36 + 4B];
  _63 = subgraph_idx_1 * 4;
  p_64 = _62 + _63;
  _65 = MEM[(const long unsigned int *)p_64];
  _66 = p_64 + _65;
  if (_66 != 0B)
    goto <bb 9>;
  else
    goto <bb 3>;

  <bb 9>:
  _14 = this_13(D)->memory_allocator_;
  _15 = _14->_vptr.SimpleMemoryAllocator;
  _16 = MEM[(int (*__vtbl_ptr_type) () *)_15 + 12B];
  _47 = &MEM[(const struct Table *)_66].data_;
  _48 = MEM[(const long int *)_66];
  _49 = (sizetype) _48;
  _50 = -_49;
  _51 = _47 + _50;
  _52 = MEM[(const short unsigned int *)_51];
  _53 = (int) _52;
  if (_53 > 10)
    goto <bb 10>;
  else
    goto <bb 15>;

  <bb 10>:
  _54 = MEM[(const short unsigned int *)_51 + 10B];
  _56 = (sizetype) _54;
  p_57 = _47 + _56;
  if (_54 != 0)
    goto <bb 11>;
  else
    goto <bb 15>;

  <bb 11>:
  _58 = MEM[(const long unsigned int *)p_57];
  iftmp.31_59 = p_57 + _58;
  _46 = iftmp.31_59->length_;
  _19 = _46 * 44;
  _21 = OBJ_TYPE_REF(_16;(struct SimpleMemoryAllocator)_14->3) (_14, _19, 4);
  if (_21 == 0B)
    goto <bb 13>;
  else
    goto <bb 12>;

  <bb 12>:
  _22 = subgraph_idx_1 * 8;
  _23 = subgraph_allocations_5(D) + _22;
  _23->node_and_registrations = _21;
  subgraph_idx_25 = subgraph_idx_1 + 1;
  goto <bb 5>;

  <bb 13>:
  # _2 = PHI <1(11), 0(7)>
  return _2;

  <bb 14>:
  _84 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 15>:
  _67 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

}



;; Function virtual TfLiteStatus tflite::MicroAllocator::AllocateTfLiteEvalTensors(const tflite::Model*, tflite::SubgraphAllocations*) (_ZN6tflite14MicroAllocator25AllocateTfLiteEvalTensorsEPKNS_5ModelEPNS_19SubgraphAllocationsE, funcdef_no=6658, decl_uid=180572, cgraph_uid=3790, symbol_order=3831)


Analyzing loop at C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: ===== analyze_loop_nest =====
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: === vect_analyze_loop_form ===
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: not vectorized: control flow in loop.
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: bad loop form.

Analyzing loop at C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: ===== analyze_loop_nest =====
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: === vect_analyze_loop_form ===
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: not vectorized: control flow in loop.
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: bad loop form.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:833:14: note: vectorized 0 loops in function.
virtual TfLiteStatus tflite::MicroAllocator::AllocateTfLiteEvalTensors(const tflite::Model*, tflite::SubgraphAllocations*) (struct MicroAllocator * const this, const struct Model * model, struct SubgraphAllocations * subgraph_allocations)
{
  const uint8_t * p;
  const struct Buffer * D.242403;
  static const char __PRETTY_FUNCTION__[246] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = flatbuffers::Offset<tflite::Buffer>; flatbuffers::Vector<T>::return_type = const tflite::Buffer*; flatbuffers::uoffset_t = long unsigned int]";
  void * out_buffer;
  unsigned char * p;
  void * D.242399;
  unsigned char * p;
  TfLiteStatus D.242394;
  const uint8_t * p;
  const struct Tensor * D.242387;
  static const char __PRETTY_FUNCTION__[246] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = flatbuffers::Offset<tflite::Tensor>; flatbuffers::Vector<T>::return_type = const tflite::Tensor*; flatbuffers::uoffset_t = long unsigned int]";
  const uint8_t * p;
  const struct SubGraph * D.242383;
  static const char __PRETTY_FUNCTION__[250] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = flatbuffers::Offset<tflite::SubGraph>; flatbuffers::Vector<T>::return_type = const tflite::SubGraph*; flatbuffers::uoffset_t = long unsigned int]";
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  size_t i;
  size_t subgraph_idx;
  TfLiteStatus _3;
  short unsigned int _10;
  const uint8_t * _11;
  sizetype _12;
  sizetype _15;
  long int _16;
  struct SimpleMemoryAllocator * _18;
  int (*__vtbl_ptr_type) () * _19;
  int (*__vtbl_ptr_type) () _20;
  unsigned int _21;
  struct TfLiteEvalTensor * _23;
  const uint8_t[1] * pretmp_26;
  long unsigned int _28;
  struct ErrorReporter * _29;
  unsigned int _30;
  struct TfLiteEvalTensor * _31;
  unsigned int _35;
  struct SubgraphAllocations * _36;
  int _41;
  short unsigned int _42;
  sizetype _44;
  long unsigned int _46;
  const struct Vector * iftmp.27_47;
  long unsigned int _58;
  const uint8_t[1] * _59;
  long int _60;
  sizetype _61;
  sizetype _62;
  const uint8_t * _63;
  short unsigned int _64;
  int _65;
  short unsigned int _66;
  long unsigned int _67;
  sizetype _68;
  long unsigned int _70;
  const struct Vector * iftmp.41_71;
  long int _73;
  sizetype _74;
  sizetype _75;
  const uint8_t * _76;
  short unsigned int _77;
  int _78;
  short unsigned int _79;
  sizetype _81;
  long unsigned int _83;
  const struct Vector * iftmp.42_84;
  const struct Vector * iftmp.42_85;
  long int _86;
  sizetype _87;
  sizetype _88;
  const uint8_t * _89;
  short unsigned int _90;
  int _91;
  short unsigned int _92;
  sizetype _94;
  long unsigned int _96;
  const struct Vector * iftmp.41_97;
  const uint8_t * _100;
  long unsigned int _101;
  long unsigned int _103;
  const struct SubGraph * _104;
  long unsigned int _105;
  const uint8_t * _106;
  long unsigned int _107;
  long unsigned int _109;
  const struct Tensor * _110;
  const uint8_t[1] * _111;
  long int _112;
  sizetype _113;
  sizetype _114;
  const uint8_t * _115;
  short unsigned int _116;
  int _117;
  short unsigned int _118;
  sizetype _120;
  const void * _121;
  signed char _122;
  TfLiteType * _125;
  TfLiteStatus _126;
  short unsigned int _134;
  long unsigned int _138;
  const struct Vector * iftmp.13_139;
  long int _143;
  sizetype _144;
  sizetype _145;
  const uint8_t * _146;
  short unsigned int _147;
  int _148;
  short unsigned int _149;
  sizetype _151;
  const void * _152;
  long unsigned int _153;
  long unsigned int iftmp.1_154;
  const uint8_t[1] * _156;
  long int _157;
  sizetype _158;
  sizetype _159;
  const uint8_t * _160;
  short unsigned int _161;
  int _162;
  short unsigned int _163;
  sizetype _165;
  long unsigned int _167;
  const struct Vector * iftmp.3_168;
  long unsigned int _170;
  const uint8_t * _171;
  long unsigned int _173;
  const uint8_t * _174;
  long unsigned int _175;
  long unsigned int _177;
  const struct Buffer * _178;
  long unsigned int _233;
  sizetype _244;
  long unsigned int _248;
  TensorType _273;
  TensorType prephitmp_274;

  <bb 2>:
  if (subgraph_allocations_7(D) != 0B)
    goto <bb 4>;
  else
    goto <bb 3>;

  <bb 3>:
  abort ();

  <bb 4>:
  pretmp_26 = &MEM[(const struct Table *)model_9(D)].data_;

  <bb 5>:
  # subgraph_idx_1 = PHI <0(4), subgraph_idx_38(43)>
  _16 = MEM[(const long int *)model_9(D)];
  _15 = (sizetype) _16;
  _12 = -_15;
  _11 = pretmp_26 + _12;
  _10 = MEM[(const short unsigned int *)_11];
  _41 = (int) _10;
  if (_41 > 8)
    goto <bb 6>;
  else
    goto <bb 48>;

  <bb 6>:
  _42 = MEM[(const short unsigned int *)_11 + 8B];
  _44 = (sizetype) _42;
  p_45 = pretmp_26 + _44;
  if (_42 != 0)
    goto <bb 7>;
  else
    goto <bb 48>;

  <bb 7>:
  _46 = MEM[(const long unsigned int *)p_45];
  iftmp.27_47 = p_45 + _46;
  _28 = iftmp.27_47->length_;
  if (subgraph_idx_1 < _28)
    goto <bb 8>;
  else
    goto <bb 44>;

  <bb 8>:
  _100 = &MEM[(void *)iftmp.27_47 + 4B];
  _101 = subgraph_idx_1 * 4;
  p_102 = _100 + _101;
  _103 = MEM[(const long unsigned int *)p_102];
  _104 = p_102 + _103;
  if (_104 != 0B)
    goto <bb 9>;
  else
    goto <bb 3>;

  <bb 9>:
  _59 = &MEM[(const struct Table *)_104].data_;
  _60 = MEM[(const long int *)_104];
  _61 = (sizetype) _60;
  _62 = -_61;
  _63 = _59 + _62;
  _64 = MEM[(const short unsigned int *)_63];
  _65 = (int) _64;
  if (_65 > 4)
    goto <bb 10>;
  else
    goto <bb 49>;

  <bb 10>:
  _66 = MEM[(const short unsigned int *)_63 + 4B];
  _68 = (sizetype) _66;
  p_69 = _59 + _68;
  if (_66 != 0)
    goto <bb 11>;
  else
    goto <bb 49>;

  <bb 11>:
  _70 = MEM[(const long unsigned int *)p_69];
  iftmp.41_71 = p_69 + _70;
  _58 = iftmp.41_71->length_;
  _18 = this_17(D)->memory_allocator_;
  _19 = _18->_vptr.SimpleMemoryAllocator;
  _20 = MEM[(int (*__vtbl_ptr_type) () *)_19 + 12B];
  _21 = _58 * 12;
  _23 = OBJ_TYPE_REF(_20;(struct SimpleMemoryAllocator)_18->3) (_18, _21, 4);
  if (_23 == 0B)
    goto <bb 12>;
  else
    goto <bb 13>;

  <bb 12>:
  goto <bb 44>;

  <bb 13>:
  if (_58 == 0)
    goto <bb 43>;
  else
    goto <bb 14>;

  <bb 14>:

  <bb 15>:
  # i_172 = PHI <0(14), i_34(47)>
  _86 = MEM[(const long int *)_104];
  _87 = (sizetype) _86;
  _88 = -_87;
  _89 = _59 + _88;
  _90 = MEM[(const short unsigned int *)_89];
  _91 = (int) _90;
  if (_91 > 4)
    goto <bb 16>;
  else
    goto <bb 50>;

  <bb 16>:
  _92 = MEM[(const short unsigned int *)_89 + 4B];
  _94 = (sizetype) _92;
  p_95 = _59 + _94;
  if (_92 != 0)
    goto <bb 17>;
  else
    goto <bb 50>;

  <bb 17>:
  _96 = MEM[(const long unsigned int *)p_95];
  iftmp.41_97 = p_95 + _96;
  _105 = iftmp.41_97->length_;
  if (_105 > i_172)
    goto <bb 19>;
  else
    goto <bb 18>;

  <bb 18>:
  __assert_func ("C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h", 262, &__PRETTY_FUNCTION__, "i < size()");

  <bb 19>:
  _106 = &MEM[(void *)iftmp.41_97 + 4B];
  _107 = i_172 * 4;
  p_108 = _106 + _107;
  _109 = MEM[(const long unsigned int *)p_108];
  _110 = p_108 + _109;
  _73 = MEM[(const long int *)model_9(D)];
  _74 = (sizetype) _73;
  _75 = -_74;
  _76 = pretmp_26 + _75;
  _77 = MEM[(const short unsigned int *)_76];
  _78 = (int) _77;
  if (_78 > 12)
    goto <bb 20>;
  else
    goto <bb 22>;

  <bb 20>:
  _79 = MEM[(const short unsigned int *)_76 + 12B];
  _81 = (sizetype) _79;
  p_82 = pretmp_26 + _81;
  if (_79 != 0)
    goto <bb 21>;
  else
    goto <bb 22>;

  <bb 21>:
  _83 = MEM[(const long unsigned int *)p_82];
  iftmp.42_84 = p_82 + _83;

  <bb 22>:
  # iftmp.42_85 = PHI <0B(20), iftmp.42_84(21), 0B(19)>
  _29 = this_17(D)->error_reporter_;
  _30 = i_172 * 12;
  _31 = _23 + _30;
  *_31 = {};
  _111 = &MEM[(const struct Table *)_110].data_;
  _112 = MEM[(const long int *)_110];
  _113 = (sizetype) _112;
  _114 = -_113;
  _115 = _111 + _114;
  _116 = MEM[(const short unsigned int *)_115];
  _117 = (int) _116;
  if (_117 > 6)
    goto <bb 23>;
  else
    goto <bb 25>;

  <bb 23>:
  _118 = MEM[(const short unsigned int *)_115 + 6B];
  if (_118 != 0)
    goto <bb 24>;
  else
    goto <bb 25>;

  <bb 24>:
  _120 = (sizetype) _118;
  _121 = _111 + _120;
  _122 = MEM[(const signed char *)_121];
  _273 = (TensorType) _122;

  <bb 25>:
  # prephitmp_274 = PHI <0(23), _273(24), 0(22)>
  _125 = &_31->type;
  _126 = tflite::ConvertTensorType (prephitmp_274, _125, _29);
  if (_126 != 0)
    goto <bb 12>;
  else
    goto <bb 26>;

  <bb 26>:
  _143 = MEM[(const long int *)_110];
  _144 = (sizetype) _143;
  _145 = -_144;
  _146 = _111 + _145;
  _147 = MEM[(const short unsigned int *)_146];
  _148 = (int) _147;
  if (_148 > 8)
    goto <bb 27>;
  else
    goto <bb 29>;

  <bb 27>:
  _149 = MEM[(const short unsigned int *)_146 + 8B];
  if (_149 != 0)
    goto <bb 28>;
  else
    goto <bb 29>;

  <bb 28>:
  _151 = (sizetype) _149;
  _152 = _111 + _151;
  _153 = MEM[(const long unsigned int *)_152];

  <bb 29>:
  # iftmp.1_154 = PHI <0(27), _153(28), 0(26)>
  _173 = iftmp.42_85->length_;
  if (iftmp.1_154 < _173)
    goto <bb 31>;
  else
    goto <bb 30>;

  <bb 30>:
  __assert_func ("C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h", 262, &__PRETTY_FUNCTION__, "i < size()");

  <bb 31>:
  _174 = &MEM[(void *)iftmp.42_85 + 4B];
  _175 = iftmp.1_154 * 4;
  p_176 = _174 + _175;
  _177 = MEM[(const long unsigned int *)p_176];
  _178 = p_176 + _177;
  if (_178 != 0B)
    goto <bb 32>;
  else
    goto <bb 45>;

  <bb 32>:
  _156 = &MEM[(const struct Table *)_178].data_;
  _157 = MEM[(const long int *)_178];
  _158 = (sizetype) _157;
  _159 = -_158;
  _160 = _156 + _159;
  _161 = MEM[(const short unsigned int *)_160];
  _162 = (int) _161;
  if (_162 > 4)
    goto <bb 33>;
  else
    goto <bb 45>;

  <bb 33>:
  _163 = MEM[(const short unsigned int *)_160 + 4B];
  _165 = (sizetype) _163;
  p_166 = _156 + _165;
  if (_163 != 0)
    goto <bb 34>;
  else
    goto <bb 37>;

  <bb 34>:
  _167 = MEM[(const long unsigned int *)p_166];
  iftmp.3_168 = p_166 + _167;
  if (iftmp.3_168 != 0B)
    goto <bb 35>;
  else
    goto <bb 45>;

  <bb 35>:
  _170 = iftmp.3_168->length_;
  if (_170 != 0)
    goto <bb 36>;
  else
    goto <bb 45>;

  <bb 36>:
  _171 = &MEM[(void *)iftmp.3_168 + 4B];
  goto <bb 45>;

  <bb 37>:
  _31->data.data = 0B;
  if (_148 > 4)
    goto <bb 39>;
  else
    goto <bb 38>;

  <bb 38>:
  _31->dims = &kZeroLengthIntArray;
  goto <bb 46>;

  <bb 39>:
  _134 = MEM[(const short unsigned int *)_146 + 4B];
  if (_134 != 0)
    goto <bb 40>;
  else
    goto <bb 38>;

  <bb 40>:
  _244 = (sizetype) _134;
  p_245 = _111 + _244;
  _138 = MEM[(const long unsigned int *)p_245];
  iftmp.13_139 = p_245 + _138;
  if (iftmp.13_139 == 0B)
    goto <bb 38>;
  else
    goto <bb 41>;

  <bb 41>:
  if (_29 != 0B)
    goto <bb 42>;
  else
    goto <bb 3>;

  <bb 42>:
  MEM[(struct TfLiteIntArray * *)_31 + 4B] = iftmp.13_139;
  goto <bb 46>;

  <bb 43>:
  _35 = subgraph_idx_1 * 8;
  _36 = subgraph_allocations_7(D) + _35;
  _36->tensors = _23;
  subgraph_idx_38 = subgraph_idx_1 + 1;
  goto <bb 5>;

  <bb 44>:
  # _3 = PHI <1(12), 0(7)>
  return _3;

  <bb 45>:
  # out_buffer_240 = PHI <_171(36), 0B(32), 0B(31), 0B(35), 0B(34)>
  _31->data.data = out_buffer_240;
  if (_148 > 4)
    goto <bb 39>;
  else
    goto <bb 38>;

  <bb 46>:
  i_34 = i_172 + 1;
  if (i_34 >= _58)
    goto <bb 43>;
  else
    goto <bb 47>;

  <bb 47>:
  goto <bb 15>;

  <bb 48>:
  _67 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 49>:
  _248 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 50>:
  _233 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

}



;; Function TfLiteStatus tflite::internal::InitializeTfLiteTensorFromFlatbuffer(tflite::SimpleMemoryAllocator*, bool, const tflite::Tensor&, const flatbuffers::Vector<flatbuffers::Offset<tflite::Buffer> >*, tflite::ErrorReporter*, TfLiteTensor*) (_ZN6tflite8internal36InitializeTfLiteTensorFromFlatbufferEPNS_21SimpleMemoryAllocatorEbRKNS_6TensorEPKN11flatbuffers6VectorINS6_6OffsetINS_6BufferEEEEEPNS_13ErrorReporterEP12TfLiteTensor, funcdef_no=6637, decl_uid=180489, cgraph_uid=3769, symbol_order=3810)


Analyzing loop at ../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:526
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:526:24: note: ===== analyze_loop_nest =====
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:526:24: note: === vect_analyze_loop_form ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:526:24: note: not vectorized: control flow in loop.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:526:24: note: bad loop form.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:423:14: note: vectorized 0 loops in function.
TfLiteStatus tflite::internal::InitializeTfLiteTensorFromFlatbuffer(tflite::SimpleMemoryAllocator*, bool, const tflite::Tensor&, const flatbuffers::Vector<flatbuffers::Offset<tflite::Buffer> >*, tflite::ErrorReporter*, TfLiteTensor*) (struct SimpleMemoryAllocator * allocator, bool allocate_temp, const struct Tensor & flatbuffer_tensor, const struct Vector * buffers, struct ErrorReporter * error_reporter, struct TfLiteTensor * result)
{
  const uint8_t * p;
  const struct Buffer * D.242446;
  static const char __PRETTY_FUNCTION__[246] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = flatbuffers::Offset<tflite::Buffer>; flatbuffers::Vector<T>::return_type = const tflite::Buffer*; flatbuffers::uoffset_t = long unsigned int]";
  unsigned char * p;
  void * out_buffer;
  void * D.242442;
  unsigned char * p;
  static const char __PRETTY_FUNCTION__[216] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = long long int; flatbuffers::Vector<T>::return_type = long long int; flatbuffers::uoffset_t = long unsigned int]";
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  static const char __PRETTY_FUNCTION__[216] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = long long int; flatbuffers::Vector<T>::return_type = long long int; flatbuffers::uoffset_t = long unsigned int]";
  unsigned char * p;
  static const char __PRETTY_FUNCTION__[200] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = float; flatbuffers::Vector<T>::return_type = float; flatbuffers::uoffset_t = long unsigned int]";
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  int i;
  int * zero_point_data;
  int channels;
  size_t type_size;
  TfLiteStatus _2;
  int * _3;
  struct TfLiteIntArray * iftmp.8_5;
  sizetype _16;
  TfLiteType * _17;
  const TfLiteStatus _20;
  sizetype _21;
  size_t * _29;
  const TfLiteStatus _31;
  long int _32;
  unsigned int _36;
  signed char _37;
  const void * _38;
  sizetype _39;
  short unsigned int _41;
  int _42;
  short unsigned int _44;
  long int _45;
  const uint8_t * _47;
  sizetype _48;
  int (*__vtbl_ptr_type) () * _51;
  int (*__vtbl_ptr_type) () _52;
  struct TfLiteAffineQuantization * _54;
  int (*__vtbl_ptr_type) () * _55;
  int (*__vtbl_ptr_type) () _56;
  struct TfLiteAffineQuantization * _58;
  int (*__vtbl_ptr_type) () * _59;
  int (*__vtbl_ptr_type) () _60;
  int _62;
  unsigned int _63;
  struct TfLiteIntArray * _65;
  int (*__vtbl_ptr_type) () * _66;
  int (*__vtbl_ptr_type) () _67;
  int _69;
  unsigned int _70;
  struct TfLiteIntArray * _72;
  sizetype _74;
  unsigned int i.9_77;
  unsigned int _78;
  int * _79;
  long int _80;
  int _81;
  const uint8_t[1] * _84;
  const uint8_t * _90;
  short unsigned int _91;
  int _92;
  short unsigned int _93;
  sizetype _95;
  const void * _96;
  unsigned char _97;
  long int _100;
  sizetype _101;
  sizetype _102;
  const uint8_t * _103;
  short unsigned int _104;
  int _105;
  short unsigned int _106;
  sizetype _108;
  long unsigned int _110;
  const struct Vector * iftmp.13_111;
  short unsigned int _113;
  struct TfLiteAffineQuantization * iftmp.7_114;
  sizetype _115;
  long unsigned int _117;
  const struct QuantizationParameters * iftmp.15_118;
  const uint8_t[1] * _120;
  long int _121;
  sizetype _122;
  sizetype _123;
  const uint8_t * _124;
  short unsigned int _125;
  int _126;
  short unsigned int _127;
  sizetype _129;
  long unsigned int _131;
  const struct Vector * iftmp.16_132;
  long unsigned int _134;
  short unsigned int _135;
  sizetype _137;
  long unsigned int _139;
  const struct Vector * iftmp.18_140;
  long unsigned int _142;
  float _144;
  long long int _160;
  long unsigned int _168;
  long int _169;
  sizetype _170;
  sizetype _171;
  const uint8_t * _172;
  short unsigned int _173;
  int _174;
  short unsigned int _175;
  sizetype _177;
  long unsigned int _179;
  const struct Vector * iftmp.16_180;
  long int _182;
  sizetype _183;
  sizetype _184;
  const uint8_t * _185;
  short unsigned int _186;
  int _187;
  short unsigned int _188;
  sizetype _190;
  long unsigned int _192;
  const struct Vector * iftmp.16_193;
  long unsigned int _195;
  const uint8_t * _196;
  long unsigned int _197;
  const long long int * _198;
  long long int _199;
  short unsigned int _200;
  sizetype _202;
  long unsigned int _204;
  const struct Vector * iftmp.18_205;
  short unsigned int _207;
  TfLiteAllocationType cstore_208;
  sizetype _209;
  const void * _210;
  long int _211;
  long int iftmp.19_212;
  short unsigned int _228;
  long unsigned int _229;
  sizetype _230;
  const void * _231;
  long unsigned int _232;
  long unsigned int iftmp.1_233;
  const uint8_t[1] * _235;
  long int _236;
  sizetype _237;
  sizetype _238;
  const uint8_t * _239;
  short unsigned int _240;
  int _241;
  short unsigned int _242;
  sizetype _244;
  long unsigned int _246;
  const struct Vector * iftmp.3_247;
  long unsigned int _249;
  const uint8_t * _250;
  long unsigned int _252;
  const uint8_t * _253;
  long unsigned int _254;
  long unsigned int _256;
  const struct Buffer * _257;
  bool prephitmp_342;
  bool _343;
  TensorType prephitmp_346;
  TensorType _347;
  long unsigned int _362;

  <bb 2>:
  if (result_12(D) != 0B)
    goto <bb 4>;
  else
    goto <bb 3>;

  <bb 3>:
  abort ();

  <bb 4>:
  *result_12(D) = {};
  _84 = &MEM[(const struct Table *)flatbuffer_tensor_15(D)].data_;
  _80 = MEM[(const long int *)flatbuffer_tensor_15(D)];
  _74 = (sizetype) _80;
  _48 = -_74;
  _47 = _84 + _48;
  _44 = MEM[(const short unsigned int *)_47];
  _42 = (int) _44;
  if (_42 > 6)
    goto <bb 5>;
  else
    goto <bb 7>;

  <bb 5>:
  _41 = MEM[(const short unsigned int *)_47 + 6B];
  if (_41 != 0)
    goto <bb 6>;
  else
    goto <bb 7>;

  <bb 6>:
  _39 = (sizetype) _41;
  _38 = _84 + _39;
  _37 = MEM[(const signed char *)_38];
  _347 = (TensorType) _37;

  <bb 7>:
  # prephitmp_346 = PHI <0(5), _347(6), 0(4)>
  _17 = &result_12(D)->type;
  _20 = tflite::ConvertTensorType (prephitmp_346, _17, error_reporter_18(D));
  if (_20 != 0)
    goto <bb 67>;
  else
    goto <bb 8>;

  <bb 8>:
  _32 = MEM[(const long int *)flatbuffer_tensor_15(D)];
  _21 = (sizetype) _32;
  _16 = -_21;
  _90 = _84 + _16;
  _91 = MEM[(const short unsigned int *)_90];
  _92 = (int) _91;
  if (_92 > 14)
    goto <bb 9>;
  else
    goto <bb 11>;

  <bb 9>:
  _93 = MEM[(const short unsigned int *)_90 + 14B];
  if (_93 != 0)
    goto <bb 10>;
  else
    goto <bb 11>;

  <bb 10>:
  _95 = (sizetype) _93;
  _96 = _84 + _95;
  _97 = MEM[(const unsigned char *)_96];
  _343 = _97 != 0;

  <bb 11>:
  # prephitmp_342 = PHI <0(9), _343(10), 0(8)>
  result_12(D)->is_variable = prephitmp_342;
  if (_92 > 8)
    goto <bb 12>;
  else
    goto <bb 14>;

  <bb 12>:
  _228 = MEM[(const short unsigned int *)_90 + 8B];
  if (_228 != 0)
    goto <bb 13>;
  else
    goto <bb 14>;

  <bb 13>:
  _230 = (sizetype) _228;
  _231 = _84 + _230;
  _232 = MEM[(const long unsigned int *)_231];

  <bb 14>:
  # iftmp.1_233 = PHI <0(12), _232(13), 0(11)>
  _252 = buffers_23(D)->length_;
  if (iftmp.1_233 < _252)
    goto <bb 16>;
  else
    goto <bb 15>;

  <bb 15>:
  __assert_func ("C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h", 262, &__PRETTY_FUNCTION__, "i < size()");

  <bb 16>:
  _253 = &MEM[(void *)buffers_23(D) + 4B];
  _254 = iftmp.1_233 * 4;
  p_255 = _253 + _254;
  _256 = MEM[(const long unsigned int *)p_255];
  _257 = p_255 + _256;
  if (_257 != 0B)
    goto <bb 17>;
  else
    goto <bb 22>;

  <bb 17>:
  _235 = &MEM[(const struct Table *)_257].data_;
  _236 = MEM[(const long int *)_257];
  _237 = (sizetype) _236;
  _238 = -_237;
  _239 = _235 + _238;
  _240 = MEM[(const short unsigned int *)_239];
  _241 = (int) _240;
  if (_241 > 4)
    goto <bb 18>;
  else
    goto <bb 22>;

  <bb 18>:
  _242 = MEM[(const short unsigned int *)_239 + 4B];
  _244 = (sizetype) _242;
  p_245 = _235 + _244;
  if (_242 != 0)
    goto <bb 19>;
  else
    goto <bb 22>;

  <bb 19>:
  _246 = MEM[(const long unsigned int *)p_245];
  iftmp.3_247 = p_245 + _246;
  if (iftmp.3_247 != 0B)
    goto <bb 20>;
  else
    goto <bb 22>;

  <bb 20>:
  _249 = iftmp.3_247->length_;
  if (_249 != 0)
    goto <bb 21>;
  else
    goto <bb 22>;

  <bb 21>:
  _250 = &MEM[(void *)iftmp.3_247 + 4B];
  result_12(D)->data.data = _250;
  goto <bb 23>;

  <bb 22>:
  result_12(D)->data.data = 0B;

  <bb 23>:
  # cstore_208 = PHI <2(22), 1(21)>
  result_12(D)->allocation_type = cstore_208;
  _29 = &result_12(D)->bytes;
  _31 = tflite::BytesRequiredForTensor (flatbuffer_tensor_15(D), _29, &type_size, error_reporter_18(D));
  if (_31 != 0)
    goto <bb 67>;
  else
    goto <bb 24>;

  <bb 24>:
  _100 = MEM[(const long int *)flatbuffer_tensor_15(D)];
  _101 = (sizetype) _100;
  _102 = -_101;
  _103 = _84 + _102;
  _104 = MEM[(const short unsigned int *)_103];
  _105 = (int) _104;
  if (_105 > 4)
    goto <bb 25>;
  else
    goto <bb 27>;

  <bb 25>:
  _106 = MEM[(const short unsigned int *)_103 + 4B];
  _108 = (sizetype) _106;
  p_109 = _84 + _108;
  if (_106 != 0)
    goto <bb 26>;
  else
    goto <bb 27>;

  <bb 26>:
  _110 = MEM[(const long unsigned int *)p_109];
  iftmp.13_111 = p_109 + _110;
  if (iftmp.13_111 == 0B)
    goto <bb 27>;
  else
    goto <bb 28>;

  <bb 27>:
  result_12(D)->dims = &kZeroLengthIntArray;
  goto <bb 30>;

  <bb 28>:
  if (error_reporter_18(D) != 0B)
    goto <bb 29>;
  else
    goto <bb 3>;

  <bb 29>:
  MEM[(struct TfLiteIntArray * *)result_12(D) + 8B] = iftmp.13_111;

  <bb 30>:
  if (_105 > 12)
    goto <bb 31>;
  else
    goto <bb 67>;

  <bb 31>:
  _113 = MEM[(const short unsigned int *)_103 + 12B];
  _115 = (sizetype) _113;
  p_116 = _84 + _115;
  if (_113 != 0)
    goto <bb 32>;
  else
    goto <bb 67>;

  <bb 32>:
  _117 = MEM[(const long unsigned int *)p_116];
  iftmp.15_118 = p_116 + _117;
  if (iftmp.15_118 != 0B)
    goto <bb 33>;
  else
    goto <bb 67>;

  <bb 33>:
  _120 = &MEM[(const struct Table *)iftmp.15_118].data_;
  _121 = MEM[(const long int *)iftmp.15_118];
  _122 = (sizetype) _121;
  _123 = -_122;
  _124 = _120 + _123;
  _125 = MEM[(const short unsigned int *)_124];
  _126 = (int) _125;
  if (_126 > 8)
    goto <bb 34>;
  else
    goto <bb 67>;

  <bb 34>:
  _127 = MEM[(const short unsigned int *)_124 + 8B];
  _129 = (sizetype) _127;
  p_130 = _120 + _129;
  if (_127 != 0)
    goto <bb 35>;
  else
    goto <bb 67>;

  <bb 35>:
  _131 = MEM[(const long unsigned int *)p_130];
  iftmp.16_132 = p_130 + _131;
  if (iftmp.16_132 != 0B)
    goto <bb 36>;
  else
    goto <bb 67>;

  <bb 36>:
  _134 = iftmp.16_132->length_;
  if (_134 != 0)
    goto <bb 37>;
  else
    goto <bb 67>;

  <bb 37>:
  if (_126 > 10)
    goto <bb 38>;
  else
    goto <bb 67>;

  <bb 38>:
  _135 = MEM[(const short unsigned int *)_124 + 10B];
  _137 = (sizetype) _135;
  p_138 = _120 + _137;
  if (_135 != 0)
    goto <bb 39>;
  else
    goto <bb 67>;

  <bb 39>:
  _139 = MEM[(const long unsigned int *)p_138];
  iftmp.18_140 = p_138 + _139;
  if (iftmp.18_140 != 0B)
    goto <bb 40>;
  else
    goto <bb 67>;

  <bb 40>:
  _142 = iftmp.18_140->length_;
  if (_142 != 0)
    goto <bb 41>;
  else
    goto <bb 67>;

  <bb 41>:
  _144 = MEM[(const float *)iftmp.16_132 + 4B];
  result_12(D)->params.scale = _144;
  _160 = MEM[(const long long int *)iftmp.18_140 + 4B];
  _45 = (long int) _160;
  result_12(D)->params.zero_point = _45;
  _169 = MEM[(const long int *)iftmp.15_118];
  _170 = (sizetype) _169;
  _171 = -_170;
  _172 = _120 + _171;
  _173 = MEM[(const short unsigned int *)_172];
  _174 = (int) _173;
  if (_174 > 8)
    goto <bb 43>;
  else
    goto <bb 68>;

  <bb 42>:
  __assert_func ("C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h", 262, &__PRETTY_FUNCTION__, "i < size()");

  <bb 43>:
  _175 = MEM[(const short unsigned int *)_172 + 8B];
  _177 = (sizetype) _175;
  p_178 = _120 + _177;
  if (_175 != 0)
    goto <bb 44>;
  else
    goto <bb 68>;

  <bb 44>:
  _179 = MEM[(const long unsigned int *)p_178];
  iftmp.16_180 = p_178 + _179;
  _168 = iftmp.16_180->length_;
  channels_49 = (int) _168;
  if (allocate_temp_50(D) != 0)
    goto <bb 45>;
  else
    goto <bb 47>;

  <bb 45>:
  _51 = allocator_33(D)->_vptr.SimpleMemoryAllocator;
  _52 = MEM[(int (*__vtbl_ptr_type) () *)_51 + 16B];
  _54 = OBJ_TYPE_REF(_52;(struct SimpleMemoryAllocator)allocator_33(D)->4) (allocator_33(D), 12, 4);
  if (_54 == 0B)
    goto <bb 46>;
  else
    goto <bb 48>;

  <bb 46>:
  goto <bb 67>;

  <bb 47>:
  _55 = allocator_33(D)->_vptr.SimpleMemoryAllocator;
  _56 = MEM[(int (*__vtbl_ptr_type) () *)_55 + 12B];
  _58 = OBJ_TYPE_REF(_56;(struct SimpleMemoryAllocator)allocator_33(D)->3) (allocator_33(D), 12, 4);
  if (_58 == 0B)
    goto <bb 46>;
  else
    goto <bb 49>;

  <bb 48>:
  _59 = allocator_33(D)->_vptr.SimpleMemoryAllocator;
  _60 = MEM[(int (*__vtbl_ptr_type) () *)_59 + 16B];
  _62 = TfLiteIntArrayGetSizeInBytes (channels_49);
  _63 = (unsigned int) _62;
  _65 = OBJ_TYPE_REF(_60;(struct SimpleMemoryAllocator)allocator_33(D)->4) (allocator_33(D), _63, 4);
  goto <bb 50>;

  <bb 49>:
  _66 = allocator_33(D)->_vptr.SimpleMemoryAllocator;
  _67 = MEM[(int (*__vtbl_ptr_type) () *)_66 + 12B];
  _69 = TfLiteIntArrayGetSizeInBytes (channels_49);
  _70 = (unsigned int) _69;
  _72 = OBJ_TYPE_REF(_67;(struct SimpleMemoryAllocator)allocator_33(D)->3) (allocator_33(D), _70, 4);

  <bb 50>:
  # iftmp.8_5 = PHI <_65(48), _72(49)>
  # iftmp.7_114 = PHI <_54(48), _58(49)>
  iftmp.7_114->zero_point = iftmp.8_5;
  if (iftmp.8_5 == 0B)
    goto <bb 46>;
  else
    goto <bb 51>;

  <bb 51>:
  _182 = MEM[(const long int *)iftmp.15_118];
  _183 = (sizetype) _182;
  _184 = -_183;
  _185 = _120 + _184;
  _186 = MEM[(const short unsigned int *)_185];
  _187 = (int) _186;
  if (_187 > 8)
    goto <bb 52>;
  else
    goto <bb 3>;

  <bb 52>:
  _188 = MEM[(const short unsigned int *)_185 + 8B];
  _190 = (sizetype) _188;
  p_191 = _120 + _190;
  if (_188 != 0)
    goto <bb 53>;
  else
    goto <bb 3>;

  <bb 53>:
  _192 = MEM[(const long unsigned int *)p_191];
  iftmp.16_193 = p_191 + _192;
  if (error_reporter_18(D) != 0B)
    goto <bb 54>;
  else
    goto <bb 3>;

  <bb 54>:
  if (iftmp.16_193 != 0B)
    goto <bb 55>;
  else
    goto <bb 3>;

  <bb 55>:
  MEM[(struct TfLiteFloatArray * *)iftmp.7_114] = iftmp.16_193;
  iftmp.8_5->size = channels_49;
  zero_point_data_76 = &iftmp.8_5->data;
  if (channels_49 <= 0)
    goto <bb 56>;
  else
    goto <bb 57>;

  <bb 56>:
  if (_187 > 16)
    goto <bb 64>;
  else
    goto <bb 66>;

  <bb 57>:
  if (_187 > 10)
    goto <bb 59>;
  else
    goto <bb 58>;

  <bb 58>:
  _36 = 0;
  _3 = zero_point_data_76 + _36;
  goto <bb 69>;

  <bb 59>:

  <bb 60>:
  # i_251 = PHI <0(59), i_83(63)>
  i.9_77 = (unsigned int) i_251;
  _78 = i.9_77 * 4;
  _79 = zero_point_data_76 + _78;
  _200 = MEM[(const short unsigned int *)_185 + 10B];
  _202 = (sizetype) _200;
  p_203 = _120 + _202;
  if (_200 != 0)
    goto <bb 61>;
  else
    goto <bb 69>;

  <bb 61>:
  _204 = MEM[(const long unsigned int *)p_203];
  iftmp.18_205 = p_203 + _204;
  _195 = iftmp.18_205->length_;
  if (i.9_77 < _195)
    goto <bb 62>;
  else
    goto <bb 42>;

  <bb 62>:
  _196 = &MEM[(void *)iftmp.18_205 + 4B];
  _197 = i.9_77 * 8;
  _198 = _196 + _197;
  _199 = *_198;
  _81 = (int) _199;
  *_79 = _81;
  i_83 = i_251 + 1;
  if (channels_49 <= i_83)
    goto <bb 56>;
  else
    goto <bb 63>;

  <bb 63>:
  goto <bb 60>;

  <bb 64>:
  _207 = MEM[(const short unsigned int *)_185 + 16B];
  if (_207 != 0)
    goto <bb 65>;
  else
    goto <bb 66>;

  <bb 65>:
  _209 = (sizetype) _207;
  _210 = _120 + _209;
  _211 = MEM[(const long int *)_210];

  <bb 66>:
  # iftmp.19_212 = PHI <0(64), _211(65), 0(56)>
  iftmp.7_114->quantized_dimension = iftmp.19_212;
  result_12(D)->quantization.type = 1;
  result_12(D)->quantization.params = iftmp.7_114;

  <bb 67>:
  # _2 = PHI <_20(7), _31(23), 0(66), 1(46), 0(31), 0(30), 0(40), 0(39), 0(38), 0(37), 0(36), 0(35), 0(34), 0(33), 0(32)>
  type_size ={v} {CLOBBER};
  return _2;

  <bb 68>:
  _229 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 69>:
  _362 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

}



;; Function TfLiteStatus tflite::MicroAllocator::FinishModelAllocation(const tflite::Model*, tflite::SubgraphAllocations*, tflite::ScratchBufferHandle**) (_ZN6tflite14MicroAllocator21FinishModelAllocationEPKNS_5ModelEPNS_19SubgraphAllocationsEPPNS_19ScratchBufferHandleE, funcdef_no=6649, decl_uid=180524, cgraph_uid=3781, symbol_order=3822)


Analyzing loop at C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: ===== analyze_loop_nest =====
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: === vect_analyze_loop_form ===
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: not vectorized: control flow in loop.
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: bad loop form.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:629:14: note: vectorized 0 loops in function.
TfLiteStatus tflite::MicroAllocator::FinishModelAllocation(const tflite::Model*, tflite::SubgraphAllocations*, tflite::ScratchBufferHandle**) (struct MicroAllocator * const this, const struct Model * model, struct SubgraphAllocations * subgraph_allocations, struct ScratchBufferHandle * * scratch_buffer_handles)
{
  TfLiteStatus D.242560;
  const uint8_t * p;
  const struct SubGraph * D.242556;
  static const char __PRETTY_FUNCTION__[250] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = flatbuffers::Offset<tflite::SubGraph>; flatbuffers::Vector<T>::return_type = const tflite::SubGraph*; flatbuffers::uoffset_t = long unsigned int]";
  unsigned char * p;
  unsigned char * p;
  size_t subgraph_idx;
  TfLiteStatus _2;
  bool _7;
  long int _9;
  long unsigned int _11;
  int (*__vtbl_ptr_type) () * _14;
  int (*__vtbl_ptr_type) () _15;
  unsigned int _16;
  int (*__vtbl_ptr_type) () _21;
  unsigned int _22;
  struct SubgraphAllocations * _24;
  struct TfLiteEvalTensor * _25;
  int subgraph_idx.29_27;
  const TfLiteStatus _29;
  int (*__vtbl_ptr_type) () * _30;
  int (*__vtbl_ptr_type) () _31;
  struct TfLiteEvalTensor * _32;
  const TfLiteStatus _34;
  sizetype _38;
  sizetype _39;
  const uint8_t * _40;
  short unsigned int _41;
  int _42;
  short unsigned int _43;
  sizetype _45;
  long unsigned int _47;
  const struct Vector * iftmp.27_48;
  void * PROF_58;
  TfLiteStatus _60;
  const uint8_t * _63;
  long unsigned int _64;
  long unsigned int _66;
  const struct SubGraph * _67;
  struct SimpleMemoryAllocator * _69;
  int (*__vtbl_ptr_type) () * _70;
  int (*__vtbl_ptr_type) () _71;
  unsigned int _72;
  uint8_t * _73;
  const uint8_t[1] * pretmp_80;
  int (*__vtbl_ptr_type) () * prephitmp_82;
  struct ScratchBufferHandle * prephitmp_84;
  int (*__vtbl_ptr_type) () * pretmp_86;
  struct ScratchBufferHandle * pretmp_87;
  struct ScratchBufferHandle * pretmp_88;
  int (*__vtbl_ptr_type) () * pretmp_89;
  long unsigned int _96;
  TfLiteStatus _98;
  TfLiteStatus _99;
  TfLiteStatus _100;

  <bb 2>:
  _7 = this_6(D)->model_is_allocating_;
  if (_7 != 0)
    goto <bb 3>;
  else
    goto <bb 23>;

  <bb 3>:
  pretmp_80 = &MEM[(const struct Table *)model_8(D)].data_;

  <bb 4>:
  # subgraph_idx_1 = PHI <0(3), subgraph_idx_35(21)>
  _9 = MEM[(const long int *)model_8(D)];
  _38 = (sizetype) _9;
  _39 = -_38;
  _40 = pretmp_80 + _39;
  _41 = MEM[(const short unsigned int *)_40];
  _42 = (int) _41;
  if (_42 > 8)
    goto <bb 5>;
  else
    goto <bb 24>;

  <bb 5>:
  _43 = MEM[(const short unsigned int *)_40 + 8B];
  _45 = (sizetype) _43;
  p_46 = pretmp_80 + _45;
  if (_43 != 0)
    goto <bb 6>;
  else
    goto <bb 24>;

  <bb 6>:
  _47 = MEM[(const long unsigned int *)p_46];
  iftmp.27_48 = p_46 + _47;
  _11 = iftmp.27_48->length_;
  if (subgraph_idx_1 < _11)
    goto <bb 7>;
  else
    goto <bb 22>;

  <bb 7>:
  _63 = &MEM[(void *)iftmp.27_48 + 4B];
  _64 = subgraph_idx_1 * 4;
  p_65 = _63 + _64;
  _66 = MEM[(const long unsigned int *)p_65];
  _67 = p_65 + _66;
  if (_67 != 0B)
    goto <bb 9>;
  else
    goto <bb 8>;

  <bb 8>:
  abort ();

  <bb 9>:
  _14 = this_6(D)->_vptr.MicroAllocator;
  _15 = MEM[(int (*__vtbl_ptr_type) () *)_14 + 48B];
  _16 = this_6(D)->scratch_buffer_request_count_;
  PROF_58 = [obj_type_ref] OBJ_TYPE_REF(_15;(struct MicroAllocator)this_6(D)->12);
  if (PROF_58 == AllocateScratchBufferHandles)
    goto <bb 10>;
  else
    goto <bb 14>;

  <bb 10>:
  if (scratch_buffer_handles_17(D) != 0B)
    goto <bb 11>;
  else
    goto <bb 8>;

  <bb 11>:
  if (_16 == 0)
    goto <bb 12>;
  else
    goto <bb 13>;

  <bb 12>:
  pretmp_87 = *scratch_buffer_handles_17(D);
  goto <bb 17>;

  <bb 13>:
  _69 = this_6(D)->memory_allocator_;
  _70 = _69->_vptr.SimpleMemoryAllocator;
  _71 = MEM[(int (*__vtbl_ptr_type) () *)_70 + 12B];
  _72 = _16 * 4;
  _73 = OBJ_TYPE_REF(_71;(struct SimpleMemoryAllocator)_69->3) (_69, _72, 4);
  *scratch_buffer_handles_17(D) = _73;
  pretmp_86 = this_6(D)->_vptr.MicroAllocator;
  goto <bb 17>;

  <bb 14>:
  _60 = OBJ_TYPE_REF(_15;(struct MicroAllocator)this_6(D)->12) (this_6(D), scratch_buffer_handles_17(D), _16);
  if (_60 != 0)
    goto <bb 15>;
  else
    goto <bb 16>;

  <bb 15>:
  # _98 = PHI <_60(14)>
  goto <bb 23>;

  <bb 16>:
  pretmp_89 = this_6(D)->_vptr.MicroAllocator;
  pretmp_88 = *scratch_buffer_handles_17(D);

  <bb 17>:
  # prephitmp_82 = PHI <pretmp_89(16), pretmp_86(13), _14(12)>
  # prephitmp_84 = PHI <pretmp_88(16), _73(13), pretmp_87(12)>
  _21 = MEM[(int (*__vtbl_ptr_type) () *)prephitmp_82 + 44B];
  _22 = subgraph_idx_1 * 8;
  _24 = subgraph_allocations_23(D) + _22;
  _25 = _24->tensors;
  subgraph_idx.29_27 = (int) subgraph_idx_1;
  _29 = OBJ_TYPE_REF(_21;(struct MicroAllocator)this_6(D)->11) (this_6(D), model_8(D), _25, prephitmp_84, subgraph_idx.29_27);
  if (_29 != 0)
    goto <bb 18>;
  else
    goto <bb 19>;

  <bb 18>:
  # _100 = PHI <_29(17)>
  goto <bb 23>;

  <bb 19>:
  _30 = this_6(D)->_vptr.MicroAllocator;
  _31 = MEM[(int (*__vtbl_ptr_type) () *)_30 + 32B];
  _32 = _24->tensors;
  _34 = OBJ_TYPE_REF(_31;(struct MicroAllocator)this_6(D)->8) (this_6(D), _67, _32);
  if (_34 != 0)
    goto <bb 20>;
  else
    goto <bb 21>;

  <bb 20>:
  # _99 = PHI <_34(19)>
  goto <bb 23>;

  <bb 21>:
  subgraph_idx_35 = subgraph_idx_1 + 1;
  goto <bb 4>;

  <bb 22>:
  this_6(D)->model_is_allocating_ = 0;

  <bb 23>:
  # _2 = PHI <1(2), _98(15), _100(18), _99(20), 0(22)>
  return _2;

  <bb 24>:
  _96 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

}



;; Function TfLiteStatus tflite::MicroAllocator::RequestScratchBufferInArena(size_t, int, int*) (_ZN6tflite14MicroAllocator27RequestScratchBufferInArenaEjiPi, funcdef_no=6651, decl_uid=180546, cgraph_uid=3783, symbol_order=3824)


Analyzing loop at ../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ===== analyze_loop_nest =====
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_analyze_loop_form ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === get_loop_niters ===
Analyzing # of iterations of loop 1
  exit condition [1, + , 1] < _36
  bounds on difference of bases: 0 ... 4294967294
Applying pattern match.pd:695, generic-match.c:64
Applying pattern match.pd:732, generic-match.c:10709
  result:
    # of iterations (size_t) _36 + 4294967295, bounded by 4294967294
Applying pattern match.pd:1047, generic-match.c:4821
Applying pattern match.pd:83, generic-match.c:9008
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Symbolic number of iterations is (size_t) _36
Creating dr for _12->node_idx
analyze_innermost: success.
	base_address: _30
	offset from base address: 0
	constant offset from base address: 4
	step: 8
	aligned to: 64
	base_object: *_30
	Access function 0: 32
	Access function 1: {0B, +, 8}_1
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_analyze_data_refs ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: got vectype for stmt: _13 = _12->node_idx;
vector(4) int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_analyze_scalar_cycles ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Analyze phi: current_node_request_count_35 = PHI <0(3), current_node_request_count_2(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Access function of PHI: current_node_request_count_35
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Analyze phi: i_34 = PHI <0(3), i_15(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Access function of PHI: {0, +, 1}_1
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: step: 1,  init: 0
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Detected induction.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Analyze phi: current_node_request_count_35 = PHI <0(3), current_node_request_count_2(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: detected reduction: need to swap operands: current_node_request_count_2 = current_node_request_count_35 + _ifc__38;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Detected reduction.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_pattern_recog ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand i_34
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: i_34 = PHI <0(3), i_15(5)>
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: induction
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _ifc__38
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: _ifc__38 = _13 == -1 ? 1 : 0;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _ifc__38
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: _ifc__38 = _13 == -1 ? 1 : 0;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _ifc__38
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: _ifc__38 = _13 == -1 ? 1 : 0;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_analyze_data_ref_accesses ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Detected single element interleaving _12->node_idx step 8
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_mark_stmts_to_be_vectorized ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: init: phi relevant? current_node_request_count_35 = PHI <0(3), current_node_request_count_2(5)>
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: init: phi relevant? i_34 = PHI <0(3), i_15(5)>
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: init: stmt relevant? _11 = i_34 * 8;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: init: stmt relevant? _12 = _30 + _11;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: init: stmt relevant? _13 = _12->node_idx;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: init: stmt relevant? _ifc__38 = _13 == -1 ? 1 : 0;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: init: stmt relevant? current_node_request_count_2 = _ifc__38 + current_node_request_count_35;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vec_stmt_relevant_p: used out of loop.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: mark relevant 0, live 1: current_node_request_count_2 = _ifc__38 + current_node_request_count_35;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: init: stmt relevant? i_15 = i_34 + 1;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: init: stmt relevant? if (i_15 >= _36)
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: worklist: examine stmt: current_node_request_count_2 = _ifc__38 + current_node_request_count_35;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand current_node_request_count_35
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: current_node_request_count_35 = PHI <0(3), current_node_request_count_2(5)>
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: reduction
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: mark relevant 3, live 0: current_node_request_count_35 = PHI <0(3), current_node_request_count_2(5)>
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _ifc__38
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: _ifc__38 = _13 == -1 ? 1 : 0;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: mark relevant 3, live 0: _ifc__38 = _13 == -1 ? 1 : 0;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: worklist: examine stmt: _ifc__38 = _13 == -1 ? 1 : 0;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _13
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: _13 = _12->node_idx;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: mark relevant 3, live 0: _13 = _12->node_idx;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: worklist: examine stmt: _13 = _12->node_idx;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: worklist: examine stmt: current_node_request_count_35 = PHI <0(3), current_node_request_count_2(5)>
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand 0
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand current_node_request_count_2
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: current_node_request_count_2 = _ifc__38 + current_node_request_count_35;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: reduction
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: reduc-stmt defining reduc-phi in the same nest.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_analyze_data_ref_dependences ===
(compute_affine_dependence
  stmt_a: _13 = _12->node_idx;
  stmt_b: _13 = _12->node_idx;
(analyze_overlapping_iterations 
  (chrec_a = 32)
  (chrec_b = 32)
  (overlap_iterations_a = [0])
  (overlap_iterations_b = [0]))
(analyze_overlapping_iterations 
  (chrec_a = {0B, +, 8}_1)
  (chrec_b = {0B, +, 8}_1)
  (overlap_iterations_a = [0])
  (overlap_iterations_b = [0]))
)
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_determine_vectorization_factor ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining phi: current_node_request_count_35 = PHI <0(3), current_node_request_count_2(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: get vectype for scalar type:  size_t
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vectype: vector(4) unsigned int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: nunits = 4
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining phi: i_34 = PHI <0(3), i_15(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: _11 = i_34 * 8;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: skip.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: _12 = _30 + _11;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: skip.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: _13 = _12->node_idx;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: get vectype for scalar type:  int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vectype: vector(4) int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: nunits = 4
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: _ifc__38 = _13 == -1 ? 1 : 0;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: get vectype for scalar type:  unsigned int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vectype: vector(4) unsigned int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: get vectype for scalar type:  unsigned int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vectype: vector(4) unsigned int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: nunits = 4
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: current_node_request_count_2 = _ifc__38 + current_node_request_count_35;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: get vectype for scalar type:  size_t
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vectype: vector(4) unsigned int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: get vectype for scalar type:  size_t
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vectype: vector(4) unsigned int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: nunits = 4
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: i_15 = i_34 + 1;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: skip.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: if (i_15 >= _36)

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: skip.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vectorization factor = 4
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_analyze_slp ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_make_slp_decision ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_analyze_data_refs_alignment ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_compute_data_ref_alignment:
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: can't force alignment of ref: _12->node_idx
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_prune_runtime_alias_test_list ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_enhance_data_refs_alignment ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vector alignment may not be reachable
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_can_advance_ivs_p:
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Analyze phi: current_node_request_count_35 = PHI <0(3), current_node_request_count_2(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: reduc phi. skip.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Analyze phi: i_34 = PHI <0(3), i_15(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Alignment of access forced using versioning.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Versioning for alignment will be applied.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_analyze_loop_operations ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: examining phi: current_node_request_count_35 = PHI <0(3), current_node_request_count_2(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: examining phi: i_34 = PHI <0(3), i_15(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: _11 = i_34 * 8;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: irrelevant.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: _12 = _30 + _11;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: irrelevant.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: _13 = _12->node_idx;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _12->node_idx
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: not ssa-name.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: use not simple.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _12->node_idx
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: not ssa-name.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: use not simple.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Data access with gaps requires scalar epilogue loop
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: can use vec_load_lanes<OI><V4SI>
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_model_load_cost: aligned.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_model_load_cost: inside_cost = 1, prologue_cost = 0 .
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: _ifc__38 = _13 == -1 ? 1 : 0;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _13 == -1
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: not ssa-name.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: use not simple.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _13
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: _13 = _12->node_idx;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand 1
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand 0
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: current_node_request_count_2 = _ifc__38 + current_node_request_count_35;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _ifc__38
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: _ifc__38 = _13 == -1 ? 1 : 0;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand current_node_request_count_35
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: current_node_request_count_35 = PHI <0(3), current_node_request_count_2(5)>
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: reduction
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: detected reduction: current_node_request_count_2 = _ifc__38 + current_node_request_count_35;

vect_model_reduction_cost: inside_cost = 1, prologue_cost = 1, epilogue_cost = 2 .
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: i_15 = i_34 + 1;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: irrelevant.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ==> examining statement: if (i_15 >= _36)
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: irrelevant.
cost model: Adding cost of checks for loop versioning to treat misalignment.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: cost model: epilogue peel iters set to vf/2 because loop iterations are unknown .
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Cost model analysis: 
  Vector inside of loop cost: 2
  Vector prologue cost: 11
  Vector epilogue cost: 8
  Scalar iteration cost: 3
  Scalar outside cost: 1
  Vector outside cost: 19
  prologue iterations: 0
  epilogue iterations: 2
  Calculated minimum iters for profitability: 7
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note:   Runtime profitability threshold = 6
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note:   Static estimate profitability threshold = 6
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: epilog loop required
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_can_advance_ivs_p:
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Analyze phi: current_node_request_count_35 = PHI <0(3), current_node_request_count_2(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: reduc phi. skip.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Analyze phi: i_34 = PHI <0(3), i_15(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: loop vectorized
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vec_transform_loop ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Profitability threshold is 6 loop iterations.
Applying pattern match.pd:2163, generic-match.c:6467
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: created vectp.323_14
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: loop versioned for vectorization to enhance alignment

Updating SSA:
Registering new PHI nodes in block #12
Registering new PHI nodes in block #13
Registering new PHI nodes in block #4
Updating SSA information for statement _11 = i_34 * 8;
Updating SSA information for statement _12 = _30 + _11;
Updating SSA information for statement _13 = _12->node_idx;
Updating SSA information for statement _ifc__38 = _13 == -1 ? 1 : 0;
Updating SSA information for statement current_node_request_count_2 = _ifc__38 + current_node_request_count_35;
Updating SSA information for statement i_15 = i_34 + 1;
Updating SSA information for statement if (i_15 >= _36)
Registering new PHI nodes in block #5
Registering new PHI nodes in block #15
Registering new PHI nodes in block #14
Registering new PHI nodes in block #10
Updating SSA information for statement _42 = i_34 * 8;
Updating SSA information for statement _43 = _30 + _11;
Updating SSA information for statement _44 = _12->node_idx;
Updating SSA information for statement _ifc__45 = _13 == -1 ? 1 : 0;
Updating SSA information for statement current_node_request_count_46 = _ifc__38 + current_node_request_count_35;
Updating SSA information for statement i_47 = i_34 + 1;
Updating SSA information for statement if (i_15 >= _36)
Registering new PHI nodes in block #11
Registering new PHI nodes in block #6
Registering new PHI nodes in block #7

SSA replacement table
N_i -> { O_1 ... O_j } means that N_i replaces O_1, ..., O_j

current_node_request_count_16 -> { current_node_request_count_35 }
i_22 -> { i_34 }
_42 -> { _11 }
_43 -> { _12 }
_44 -> { _13 }
_ifc__45 -> { _ifc__38 }
current_node_request_count_46 -> { current_node_request_count_2 }
i_47 -> { i_15 }
Incremental SSA update started at block: 12
Number of blocks in CFG: 16
Number of blocks to update: 8 ( 50%)
Affected blocks: 4 5 6 10 11 13 14 15


Applying pattern match.pd:695, generic-match.c:64
Applying pattern match.pd:732, generic-match.c:10709
Applying pattern match.pd:695, generic-match.c:64
Applying pattern match.pd:732, generic-match.c:10709
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: === vect_do_peeling_for_loop_bound ===
Removing basic block 16
basic block 16, loop depth 0
 pred:       13
 succ:      


Applying pattern match.pd:1771, generic-match.c:1258
;; Scaling loop 1 with scale 0.666600, bounding iterations to 0 from guessed 16
;; guessed iterations are now 11
;; Scaling loop 3 with scale 0.777800, bounding iterations to 4 from guessed 14
;; guessed iterations are now 4
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_update_ivs_after_vectorizer: phi: current_node_request_count_35 = PHI <0(20), current_node_request_count_2(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: reduc phi. skip.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_update_ivs_after_vectorizer: phi: i_34 = PHI <0(20), i_15(5)>

Applying pattern match.pd:148, generic-match.c:566
Applying pattern match.pd:83, generic-match.c:9008
Setting upper bound of nb iterations for epilogue loop to 6
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ------>vectorizing phi: current_node_request_count_35 = PHI <0(24), current_node_request_count_2(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ------>vectorizing phi: i_34 = PHI <0(24), i_15(5)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ------>vectorizing statement: _11 = i_34 * 8;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ------>vectorizing statement: _12 = _30 + _11;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ------>vectorizing statement: _13 = _12->node_idx;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: transform statement.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Data access with gaps requires scalar epilogue loop
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: can use vec_load_lanes<OI><V4SI>
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: transform load. ncopies = 1
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: create array_type-pointer variable to type: int[8]  vectorizing a record based array ref: *_30
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: created vectp.330_70
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: add new stmt: vect_array.331 = LOAD_LANES (MEM[(int *)vectp.329_71]);
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: add new stmt: vect__13.332_73 = vect_array.331[0];
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: add new stmt: vect__13.333_74 = vect_array.331[1];
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ------>vectorizing statement: _ifc__38 = _13 == -1 ? 1 : 0;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: transform statement.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _13
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: _13 = _12->node_idx;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand 1
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand 0
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_get_vec_def_for_operand: _13
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _13
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: _13 = _12->node_idx;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note:   def_stmt =  _13 = _12->node_idx;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _13
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: _13 = _12->node_idx;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_get_vec_def_for_operand: -1
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand -1
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: created new init_stmt: vect_cst__75 = { -1, -1, -1, -1 };
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand -1
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_get_vec_def_for_operand: 1
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand 1
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: created new init_stmt: vect_cst__76 = { 1, 1, 1, 1 };
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand 1
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_get_vec_def_for_operand: 0
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand 0
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: created new init_stmt: vect_cst__77 = { 0, 0, 0, 0 };
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand 0
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: add new stmt: vect__ifc__38.334_78 = VEC_COND_EXPR <vect__13.332_73 == vect_cst__75, vect_cst__76, vect_cst__77>;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ------>vectorizing statement: current_node_request_count_2 = _ifc__38 + current_node_request_count_35;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: transform statement.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _ifc__38
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: _ifc__38 = _13 == -1 ? 1 : 0;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand current_node_request_count_35
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: current_node_request_count_35 = PHI <0(24), current_node_request_count_2(5)>
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: reduction
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: detected reduction: current_node_request_count_2 = _ifc__38 + current_node_request_count_35;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: transform reduction.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_get_vec_def_for_operand: _ifc__38
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand _ifc__38
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: def_stmt: _ifc__38 = _13 == -1 ? 1 : 0;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note:   def_stmt =  _ifc__38 = _13 == -1 ? 1 : 0;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: add new stmt: vect_current_node_request_count_2.335_80 = vect__ifc__38.334_78 + vect_current_node_request_count_2.335_79;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: vect_is_simple_use: operand 0
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: transform reduction: created def-use cycle: vect_current_node_request_count_2.335_79 = PHI <{ 0, 0, 0, 0 }(24), vect_current_node_request_count_2.335_80(5)>

vect_current_node_request_count_2.335_80 = vect__ifc__38.334_78 + vect_current_node_request_count_2.335_79;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: Reduce using direct vector reduction.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ------>vectorizing statement: i_15 = i_34 + 1;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ------>vectorizing statement: vectp.329_72 = vectp.329_71 + 32;

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: ------>vectorizing statement: if (i_15 >= _36)


loop at ../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:672: if (ivtmp_85 >= bnd.326_51)

;; Scaling loop 1 with scale 0.250000, bounding iterations to 2 from guessed 11
;; guessed iterations are now 1
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:671:24: note: LOOP VECTORIZED

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:661:14: note: vectorized 1 loops in function.

Updating SSA:
creating PHI node in block #4 for .MEM
creating PHI node in block #6 for .MEM
creating PHI node in block #8 for .MEM
creating PHI node in block #19 for .MEM
creating PHI node in block #22 for .MEM
Registering new PHI nodes in block #0
Registering new PHI nodes in block #2
Updating SSA information for statement _28 = this_7(D)->memory_allocator_;
Updating SSA information for statement _29 = tflite::SimpleMemoryAllocator::GetHeadBuffer (_28);
Updating SSA information for statement _30 = tflite::AlignPointerUp (_29, 4);
Updating SSA information for statement _36 = this_7(D)->scratch_buffer_request_count_;
Registering new PHI nodes in block #3
Registering new PHI nodes in block #12
Registering new PHI nodes in block #13
Registering new PHI nodes in block #20
Registering new PHI nodes in block #24
Registering new PHI nodes in block #4
Updating SSA information for statement vect_array.331 = LOAD_LANES (MEM[(int *)vectp.329_71]);
Updating SSA information for statement vect__13.332_73 = vect_array.331[0];
Updating SSA information for statement vect__13.333_74 = vect_array.331[1];
Updating SSA information for statement _13 = _12->node_idx;
Registering new PHI nodes in block #5
Registering new PHI nodes in block #21
Registering new PHI nodes in block #19
Registering new PHI nodes in block #17
Updating SSA information for statement _59 = _58->node_idx;
Registering new PHI nodes in block #18
Registering new PHI nodes in block #23
Registering new PHI nodes in block #22
Registering new PHI nodes in block #15
Registering new PHI nodes in block #14
Registering new PHI nodes in block #10
Updating SSA information for statement _44 = _43->node_idx;
Registering new PHI nodes in block #11
Registering new PHI nodes in block #6
Registering new PHI nodes in block #7
Registering new PHI nodes in block #8
Updating SSA information for statement *current_request_17 = {};
Updating SSA information for statement current_request_17->bytes = bytes_19(D);
Updating SSA information for statement current_request_17->node_idx = -1;
Updating SSA information for statement *buffer_idx_23(D) = prephitmp_41;
Updating SSA information for statement _25 = this_7(D)->scratch_buffer_request_count_;
Updating SSA information for statement this_7(D)->scratch_buffer_request_count_ = _26;
Registering new PHI nodes in block #9
Updating SSA information for statement return _4;

Symbols to be put in SSA form
{ D.241285 }
Incremental SSA update started at block: 0
Number of blocks in CFG: 25
Number of blocks to update: 23 ( 92%)
Affected blocks: 0 2 3 4 5 6 7 8 9 10 11 12 13 14 15 17 18 19 20 21 22 23 24


Removing basic block 3
basic block 3, loop depth 0
 pred:      
 succ:       12


Merging blocks 13 and 20
Merging blocks 22 and 15
Applying pattern match.pd:797, gimple-match.c:164
Applying pattern match.pd:2419, gimple-match.c:49576
fix_loop_structure: fixing up loops for function
TfLiteStatus tflite::MicroAllocator::RequestScratchBufferInArena(size_t, int, int*) (struct MicroAllocator * const this, size_t bytes, int subgraph_idx, int * buffer_idx)
{
  size_t vect_current_node_request_count_2.337;
  size_t stmp_current_node_request_count_2.336;
  vector(4) unsigned int vect_current_node_request_count_2.335;
  vector(4) unsigned int vect__ifc__38.334;
  vector(4) int vect__13.333;
  vector(4) int vect__13.332;
  vector(4) int vect_array.331[2];
  vector(4) int * vectp.330;
  int[8] * vectp.329;
  size_t tmp.328;
  size_t ratio_mult_vf.327;
  size_t bnd.326;
  size_t ni_gap.325;
  size_t niters.324;
  vector(4) int * vectp.323;
  struct ScratchBufferRequest * D.242581;
  size_t i;
  struct ScratchBufferRequest * current_request;
  size_t current_node_request_count;
  bool _1;
  bool _3;
  TfLiteStatus _4;
  unsigned int _9;
  signed int andmask_10;
  unsigned int _11;
  struct ScratchBufferRequest * _12;
  int _13;
  unsigned int _25;
  unsigned int _26;
  struct SimpleMemoryAllocator * _28;
  uint8_t * _29;
  struct ScratchBufferRequest * _30;
  bool _33;
  unsigned int _36;
  signed int addr2int0_37;
  unsigned int _ifc__38;
  unsigned int prephitmp_39;
  int _40;
  int prephitmp_41;
  unsigned int _42;
  struct ScratchBufferRequest * _43;
  int _44;
  unsigned int _ifc__45;
  unsigned int _52;
  unsigned int _53;
  unsigned int _57;
  struct ScratchBufferRequest * _58;
  int _59;
  unsigned int _ifc__60;
  unsigned int _63;
  vector(4) int vect_cst__75;
  vector(4) unsigned int vect_cst__76;
  vector(4) unsigned int vect_cst__77;
  unsigned int ivtmp_84;
  unsigned int ivtmp_85;

  <bb 2>:
  _28 = this_7(D)->memory_allocator_;
  _29 = tflite::SimpleMemoryAllocator::GetHeadBuffer (_28);
  _30 = tflite::AlignPointerUp (_29, 4);
  _36 = this_7(D)->scratch_buffer_request_count_;
  if (_36 == 0)
    goto <bb 19>;
  else
    goto <bb 3>;

  <bb 3>:
  vectp.323_14 = _30 + 4;
  addr2int0_37 = (signed int) vectp.323_14;
  andmask_10 = addr2int0_37 & 15;
  _1 = _36 > 6;
  _33 = andmask_10 == 0;
  _3 = _1 & _33;
  if (_3 != 0)
    goto <bb 4>;
  else
    goto <bb 12>;

  <bb 4>:
  niters.324_49 = _36;
  ni_gap.325_50 = niters.324_49 + 4294967295;
  _52 = ni_gap.325_50 + 4294967292;
  _53 = _52 >> 2;
  bnd.326_51 = _53 + 1;
  ratio_mult_vf.327_54 = bnd.326_51 << 2;
  _63 = _36 + 4294967295;
  if (_63 <= 3)
    goto <bb 10>;
  else
    goto <bb 5>;

  <bb 5>:
  vectp.330_70 = _30 + 4;
  vect_cst__75 = { -1, -1, -1, -1 };
  vect_cst__76 = { 1, 1, 1, 1 };
  vect_cst__77 = { 0, 0, 0, 0 };

  <bb 6>:
  # current_node_request_count_35 = PHI <0(5), current_node_request_count_2(11)>
  # i_34 = PHI <0(5), i_15(11)>
  # vectp.329_71 = PHI <vectp.330_70(5), vectp.329_72(11)>
  # vect_current_node_request_count_2.335_79 = PHI <{ 0, 0, 0, 0 }(5), vect_current_node_request_count_2.335_80(11)>
  # ivtmp_84 = PHI <0(5), ivtmp_85(11)>
  _11 = i_34 * 8;
  _12 = _30 + _11;
  vect_array.331 = LOAD_LANES (MEM[(int *)vectp.329_71]);
  vect__13.332_73 = vect_array.331[0];
  vect__13.333_74 = vect_array.331[1];
  _13 = _12->node_idx;
  vect__ifc__38.334_78 = VEC_COND_EXPR <vect__13.332_73 == vect_cst__75, vect_cst__76, vect_cst__77>;
  _ifc__38 = _13 == -1 ? 1 : 0;
  vect_current_node_request_count_2.335_80 = vect__ifc__38.334_78 + vect_current_node_request_count_2.335_79;
  current_node_request_count_2 = _ifc__38 + current_node_request_count_35;
  i_15 = i_34 + 1;
  vectp.329_72 = vectp.329_71 + 32;
  ivtmp_85 = ivtmp_84 + 1;
  if (ivtmp_85 >= bnd.326_51)
    goto <bb 9>;
  else
    goto <bb 11>;

  <bb 7>:
  # current_node_request_count_55 = PHI <current_node_request_count_61(8), current_node_request_count_64(10)>
  # i_56 = PHI <i_62(8), i_66(10)>
  _57 = i_56 * 8;
  _58 = _30 + _57;
  _59 = _58->node_idx;
  _ifc__60 = _59 == -1 ? 1 : 0;
  current_node_request_count_61 = _ifc__60 + current_node_request_count_55;
  i_62 = i_56 + 1;
  if (i_62 >= _36)
    goto <bb 15>;
  else
    goto <bb 8>;

  <bb 8>:
  goto <bb 7>;

  <bb 9>:
  # current_node_request_count_65 = PHI <current_node_request_count_2(6)>
  # i_67 = PHI <i_15(6)>
  # vect_current_node_request_count_2.335_81 = PHI <vect_current_node_request_count_2.335_80(6)>
  stmp_current_node_request_count_2.336_82 = [reduc_plus_expr] vect_current_node_request_count_2.335_81;
  vect_current_node_request_count_2.337_83 = stmp_current_node_request_count_2.336_82 + 0;
  if (niters.324_49 == ratio_mult_vf.327_54)
    goto <bb 16>;
  else
    goto <bb 10>;

  <bb 10>:
  # current_node_request_count_64 = PHI <vect_current_node_request_count_2.337_83(9), 0(4)>
  # i_66 = PHI <ratio_mult_vf.327_54(9), 0(4)>
  goto <bb 7>;

  <bb 11>:
  goto <bb 6>;

  <bb 12>:

  <bb 13>:
  # current_node_request_count_16 = PHI <0(12), current_node_request_count_46(14)>
  # i_22 = PHI <0(12), i_47(14)>
  _42 = i_22 * 8;
  _43 = _30 + _42;
  _44 = _43->node_idx;
  _ifc__45 = _44 == -1 ? 1 : 0;
  current_node_request_count_46 = _ifc__45 + current_node_request_count_16;
  i_47 = i_22 + 1;
  if (i_47 >= _36)
    goto <bb 17>;
  else
    goto <bb 14>;

  <bb 14>:
  goto <bb 13>;

  <bb 15>:
  # current_node_request_count_69 = PHI <current_node_request_count_61(7)>

  <bb 16>:
  # current_node_request_count_68 = PHI <current_node_request_count_69(15), vect_current_node_request_count_2.337_83(9)>

  <bb 17>:
  # current_node_request_count_8 = PHI <current_node_request_count_68(16), current_node_request_count_46(13)>
  if (current_node_request_count_8 > 11)
    goto <bb 20>;
  else
    goto <bb 18>;

  <bb 18>:
  _9 = _36 * 8;
  _40 = (int) _36;

  <bb 19>:
  # prephitmp_39 = PHI <_9(18), 0(2)>
  # prephitmp_41 = PHI <_40(18), 0(2)>
  current_request_17 = _30 + prephitmp_39;
  *current_request_17 = {};
  current_request_17->bytes = bytes_19(D);
  current_request_17->node_idx = -1;
  *buffer_idx_23(D) = prephitmp_41;
  _25 = this_7(D)->scratch_buffer_request_count_;
  _26 = _25 + 1;
  this_7(D)->scratch_buffer_request_count_ = _26;

  <bb 20>:
  # _4 = PHI <1(17), 0(19)>
  return _4;

}



;; Function TfLiteStatus tflite::MicroAllocator::FinishPrepareNodeAllocations(int) (_ZN6tflite14MicroAllocator28FinishPrepareNodeAllocationsEi, funcdef_no=6652, decl_uid=180549, cgraph_uid=3784, symbol_order=3825)


Analyzing loop at ../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:711
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:711:24: note: ===== analyze_loop_nest =====
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:711:24: note: === vect_analyze_loop_form ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:711:24: note: not vectorized: control flow in loop.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:711:24: note: bad loop form.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:703:14: note: vectorized 0 loops in function.
TfLiteStatus tflite::MicroAllocator::FinishPrepareNodeAllocations(int) (struct MicroAllocator * const this, int node_id)
{
  struct ScratchBufferRequest * D.242621;
  size_t i;
  int (*__vtbl_ptr_type) () * _7;
  int (*__vtbl_ptr_type) () _8;
  unsigned int _11;
  unsigned int _13;
  struct ScratchBufferRequest * _14;
  int _15;
  struct SimpleMemoryAllocator * _19;
  int (*__vtbl_ptr_type) () * _20;
  int (*__vtbl_ptr_type) () _21;
  const TfLiteStatus _25;
  void * PROF_26;
  struct SimpleMemoryAllocator * _28;
  int (*__vtbl_ptr_type) () * _29;
  int (*__vtbl_ptr_type) () _30;
  struct SimpleMemoryAllocator * _31;
  uint8_t * _32;
  struct ScratchBufferRequest * _33;
  unsigned int _43;
  unsigned int _44;
  unsigned int prephitmp_45;

  <bb 2>:
  _7 = this_6(D)->_vptr.MicroAllocator;
  _8 = MEM[(int (*__vtbl_ptr_type) () *)_7 + 8B];
  PROF_26 = [obj_type_ref] OBJ_TYPE_REF(_8;(struct MicroAllocator)this_6(D)->2);
  if (PROF_26 == ResetTempAllocations)
    goto <bb 3>;
  else
    goto <bb 4>;

  <bb 3>:
  _28 = this_6(D)->memory_allocator_;
  _29 = _28->_vptr.SimpleMemoryAllocator;
  _30 = MEM[(int (*__vtbl_ptr_type) () *)_29 + 20B];
  OBJ_TYPE_REF(_30;(struct SimpleMemoryAllocator)_28->5) (_28);
  goto <bb 5>;

  <bb 4>:
  OBJ_TYPE_REF(_8;(struct MicroAllocator)this_6(D)->2) (this_6(D));

  <bb 5>:
  _31 = this_6(D)->memory_allocator_;
  _32 = tflite::SimpleMemoryAllocator::GetHeadBuffer (_31);
  _33 = tflite::AlignPointerUp (_32, 4);
  _43 = this_6(D)->scratch_buffer_request_count_;
  if (_43 == 0)
    goto <bb 12>;
  else
    goto <bb 6>;

  <bb 6>:

  <bb 7>:
  # i_42 = PHI <0(6), i_18(10)>
  _13 = i_42 * 8;
  _14 = _33 + _13;
  _15 = _14->node_idx;
  if (_15 == -1)
    goto <bb 8>;
  else
    goto <bb 9>;

  <bb 8>:
  _14->node_idx = node_id_16(D);

  <bb 9>:
  i_18 = i_42 + 1;
  if (i_18 >= _43)
    goto <bb 11>;
  else
    goto <bb 10>;

  <bb 10>:
  goto <bb 7>;

  <bb 11>:
  _44 = _43 + 12;
  _11 = _44 * 8;

  <bb 12>:
  # prephitmp_45 = PHI <_11(11), 96(5)>
  _19 = this_6(D)->memory_allocator_;
  _20 = _19->_vptr.SimpleMemoryAllocator;
  _21 = MEM[(int (*__vtbl_ptr_type) () *)_20 + 8B];
  _25 = OBJ_TYPE_REF(_21;(struct SimpleMemoryAllocator)_19->2) (_19, prephitmp_45, 4);
  return _25;

}



;; Function virtual TfLiteStatus tflite::MicroAllocator::CommitStaticMemoryPlan(const tflite::Model*, TfLiteEvalTensor*, tflite::ScratchBufferHandle*, int) (_ZN6tflite14MicroAllocator22CommitStaticMemoryPlanEPKNS_5ModelEP16TfLiteEvalTensorPNS_19ScratchBufferHandleEi, funcdef_no=6663, decl_uid=180593, cgraph_uid=3795, symbol_order=3836)


Analyzing loop at ../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:332
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:332:55: note: ===== analyze_loop_nest =====
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:332:55: note: === vect_analyze_loop_form ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:332:55: note: not vectorized: control flow in loop.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:332:55: note: bad loop form.

Analyzing loop at ../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:307
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:307:55: note: ===== analyze_loop_nest =====
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:307:55: note: === vect_analyze_loop_form ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:307:55: note: not vectorized: control flow in loop.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:307:55: note: bad loop form.

Analyzing loop at ../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: ===== analyze_loop_nest =====
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: === vect_analyze_loop_form ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: === get_loop_niters ===
Analyzing # of iterations of loop 8
  exit condition [(size_t) _108 + 1, + , 1] < _544
  bounds on difference of bases: 0 ... 4294967295
Applying pattern match.pd:1079, generic-match.c:11479
Applying pattern match.pd:994, generic-match.c:4164
  result:
    # of iterations ((size_t) _544 - (size_t) _108) - 1, bounded by 4294967295
Applying pattern match.pd:695, generic-match.c:64
Applying pattern match.pd:732, generic-match.c:10709
Applying pattern match.pd:1028, generic-match.c:3418
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: Symbolic number of iterations is (size_t) _544 - (size_t) _108
Creating dr for current_467->output_ptr
analyze_innermost: success.
	base_address: _24 + (sizetype) (_108 * 24)
	offset from base address: 0
	constant offset from base address: 4
	step: 24
	aligned to: 64
	base_object: *_24 + (sizetype) (_108 * 24)
	Access function 0: 32
	Access function 1: {0B, +, 24}_8
Creating dr for current_request_462->bytes
analyze_innermost: Applying pattern match.pd:111, generic-match.c:10156
success.
	base_address: _474
	offset from base address: 0
	constant offset from base address: 0
	step: 8
	aligned to: 64
	base_object: *_474
	Access function 0: 0
	Access function 1: {0B, +, 8}_8
Creating dr for current_467->bytes
analyze_innermost: success.
	base_address: _24 + (sizetype) (_108 * 24)
	offset from base address: 0
	constant offset from base address: 0
	step: 24
	aligned to: 64
	base_object: *_24 + (sizetype) (_108 * 24)
	Access function 0: 0
	Access function 1: {0B, +, 24}_8
Creating dr for current_request_462->node_idx
analyze_innermost: success.
	base_address: _474
	offset from base address: 0
	constant offset from base address: 4
	step: 8
	aligned to: 64
	base_object: *_474
	Access function 0: 32
	Access function 1: {0B, +, 8}_8
Creating dr for current_467->first_created
analyze_innermost: success.
	base_address: _24 + (sizetype) (_108 * 24)
	offset from base address: 0
	constant offset from base address: 8
	step: 24
	aligned to: 64
	base_object: *_24 + (sizetype) (_108 * 24)
	Access function 0: 64
	Access function 1: {0B, +, 24}_8
Creating dr for current_467->last_used
analyze_innermost: success.
	base_address: _24 + (sizetype) (_108 * 24)
	offset from base address: 0
	constant offset from base address: 12
	step: 24
	aligned to: 64
	base_object: *_24 + (sizetype) (_108 * 24)
	Access function 0: 96
	Access function 1: {0B, +, 24}_8
Creating dr for current_467->offline_offset
analyze_innermost: success.
	base_address: _24 + (sizetype) (_108 * 24)
	offset from base address: 0
	constant offset from base address: 16
	step: 24
	aligned to: 64
	base_object: *_24 + (sizetype) (_108 * 24)
	Access function 0: 128
	Access function 1: {0B, +, 24}_8
Creating dr for current_467->needs_allocating
analyze_innermost: success.
	base_address: _24 + (sizetype) (_108 * 24)
	offset from base address: 0
	constant offset from base address: 20
	step: 24
	aligned to: 64
	base_object: *_24 + (sizetype) (_108 * 24)
	Access function 0: 160
	Access function 1: {0B, +, 24}_8
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: === vect_analyze_data_refs ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: got vectype for stmt: current_467->output_ptr = _468;
vector(4) unsigned int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: got vectype for stmt: _469 = current_request_462->bytes;
vector(4) unsigned int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: got vectype for stmt: current_467->bytes = _469;
vector(4) unsigned int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: got vectype for stmt: _470 = current_request_462->node_idx;
vector(4) int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: got vectype for stmt: current_467->first_created = _470;
vector(4) int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: got vectype for stmt: current_467->last_used = _470;
vector(4) int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: got vectype for stmt: current_467->offline_offset = -1;
vector(4) long int
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: got vectype for stmt: current_467->needs_allocating = 1;
vector(16) unsigned char
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: === vect_analyze_scalar_cycles ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: Analyze phi: i_729 = PHI <_108(97), i_471(99)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: Access function of PHI: {_108, +, 1}_8
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: step: 1,  init: _108
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: Detected induction.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: Analyze phi: .MEM_708 = PHI <.MEM_558(97), .MEM_565(99)>

../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: === vect_pattern_recog ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: vect_is_simple_use: operand _460
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: def_stmt: _460 = i_729 - _108;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: vect_is_simple_use: operand _460
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: def_stmt: _460 = i_729 - _108;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: type of def: internal
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: vect_is_simple_use: operand i_729
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: def_stmt: i_729 = PHI <_108(97), i_471(99)>
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: type of def: induction
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: === vect_analyze_data_ref_accesses ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: Detected interleaving store current_467->first_created and current_467->last_used
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: Detected interleaving store current_467->first_created and current_467->offline_offset
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: not consecutive access current_467->bytes = _469;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: using strided accesses
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: not consecutive access current_467->output_ptr = _468;
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: using strided accesses
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: interleaved store with gaps
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: not vectorized: complicated access pattern.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:284:36: note: bad data access.

Analyzing loop at ../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:229
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:229:48: note: ===== analyze_loop_nest =====
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:229:48: note: === vect_analyze_loop_form ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:229:48: note: not vectorized: multiple nested loops.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:229:48: note: bad loop form.

Analyzing loop at C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: ===== analyze_loop_nest =====
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: === vect_analyze_loop_form ===
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: not vectorized: control flow in loop.
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: bad loop form.

Analyzing loop at C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: ===== analyze_loop_nest =====
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: === vect_analyze_loop_form ===
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: not vectorized: control flow in loop.
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: bad loop form.

Analyzing loop at C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: ===== analyze_loop_nest =====
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: === vect_analyze_loop_form ===
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: not vectorized: control flow in loop.
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: bad loop form.

Analyzing loop at C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: ===== analyze_loop_nest =====
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: === vect_analyze_loop_form ===
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: not vectorized: control flow in loop.
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/base.h:392:22: note: bad loop form.

Analyzing loop at ../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:197
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:197:39: note: ===== analyze_loop_nest =====
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:197:39: note: === vect_analyze_loop_form ===
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:197:39: note: not vectorized: control flow in loop.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:197:39: note: bad loop form.

Analyzing loop at C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:262
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:262:5: note: ===== analyze_loop_nest =====
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:262:5: note: === vect_analyze_loop_form ===
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:262:5: note: not vectorized: control flow in loop.
C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h:262:5: note: bad loop form.
../src/tensorflow_lite/tensorflow/lite/micro/micro_allocator.cc:913:14: note: vectorized 0 loops in function.
virtual TfLiteStatus tflite::MicroAllocator::CommitStaticMemoryPlan(const tflite::Model*, TfLiteEvalTensor*, tflite::ScratchBufferHandle*, int) (struct MicroAllocator * const this, const struct Model * model, struct TfLiteEvalTensor * eval_tensors, struct ScratchBufferHandle * scratch_buffer_handles, int subgraph_idx)
{
  unsigned int builder$buffer_count_;
  unsigned int builder$tensor_count_;
  struct AllocationInfo * builder$info_;
  int offset;
  const struct AllocationInfo * current;
  size_t i;
  int planner_index;
  TfLiteStatus D.242732;
  const struct AllocationInfo * current;
  size_t i;
  TfLiteStatus D.242722;
  struct ScratchBufferRequest * D.242715;
  size_t i;
  struct ScratchBufferRequest * current_request;
  struct ScratchBufferHandle * current_handle;
  struct AllocationInfo * current;
  TfLiteStatus D.242713;
  const uint8_t * p;
  const struct Operator * D.242705;
  static const char __PRETTY_FUNCTION__[250] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = flatbuffers::Offset<tflite::Operator>; flatbuffers::Vector<T>::return_type = const tflite::Operator*; flatbuffers::uoffset_t = long unsigned int]";
  const uint8_t * p;
  const struct Tensor * D.242701;
  static const char __PRETTY_FUNCTION__[246] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = flatbuffers::Offset<tflite::Tensor>; flatbuffers::Vector<T>::return_type = const tflite::Tensor*; flatbuffers::uoffset_t = long unsigned int]";
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  struct AllocationInfo * current;
  size_t n;
  struct AllocationInfo * current;
  size_t n;
  int i;
  struct AllocationInfo * current;
  size_t i;
  struct AllocationInfo * current;
  size_t i;
  struct AllocationInfo * current;
  size_t i;
  TfLiteStatus D.242697;
  const uint8_t * p;
  const struct Buffer * D.242668;
  static const char __PRETTY_FUNCTION__[246] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = flatbuffers::Offset<tflite::Buffer>; flatbuffers::Vector<T>::return_type = const tflite::Buffer*; flatbuffers::uoffset_t = long unsigned int]";
  const uint8_t * p;
  const struct Metadata * D.242664;
  static const char __PRETTY_FUNCTION__[250] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = flatbuffers::Offset<tflite::Metadata>; flatbuffers::Vector<T>::return_type = const tflite::Metadata*; flatbuffers::uoffset_t = long unsigned int]";
  size_t i;
  const size_t nbr_tensors;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  TfLiteStatus D.242660;
  const uint8_t * p;
  const struct SubGraph * D.242648;
  static const char __PRETTY_FUNCTION__[250] = "flatbuffers::Vector<T>::return_type flatbuffers::Vector<T>::Get(flatbuffers::uoffset_t) const [with T = flatbuffers::Offset<tflite::SubGraph>; flatbuffers::Vector<T>::return_type = const tflite::SubGraph*; flatbuffers::uoffset_t = long unsigned int]";
  unsigned char * p;
  unsigned char * p;
  unsigned char * p;
  const TfLiteStatus s;
  struct GreedyMemoryPlanner planner;
  const int32_t * offline_planner_offsets;
  struct AllocationInfoBuilder builder;
  size_t bytes;
  size_t allocation_info_count;
  TfLiteStatus _1;
  TfLiteStatus _2;
  const uint8_t * _9;
  long unsigned int subgraph_idx.48_11;
  sizetype _14;
  sizetype _15;
  unsigned int _17;
  struct SimpleMemoryAllocator * _20;
  int (*__vtbl_ptr_type) () * _21;
  int (*__vtbl_ptr_type) () _22;
  struct AllocationInfo * _24;
  long int _25;
  const uint8_t[1] * _26;
  unsigned int _27;
  struct SimpleMemoryAllocator * _41;
  size_t _43;
  struct SimpleMemoryAllocator * _44;
  int (*__vtbl_ptr_type) () * _45;
  int (*__vtbl_ptr_type) () _46;
  uint8_t * _48;
  int remaining_arena_size.50_49;
  struct ErrorReporter * _51;
  struct SimpleMemoryAllocator * _54;
  int (*__vtbl_ptr_type) () * _55;
  int (*__vtbl_ptr_type) () _56;
  struct SimpleMemoryAllocator * _58;
  size_t _60;
  unsigned int _62;
  struct ErrorReporter * _63;
  struct SimpleMemoryAllocator * _64;
  uint8_t * _66;
  size_t _70;
  unsigned int _71;
  struct SimpleMemoryAllocator * _73;
  int (*__vtbl_ptr_type) () * _74;
  int (*__vtbl_ptr_type) () _75;
  const TfLiteStatus _78;
  short unsigned int _84;
  int _85;
  short unsigned int _86;
  long unsigned int _87;
  sizetype _88;
  long unsigned int _90;
  const struct Vector * iftmp.27_91;
  const uint8_t[1] * pretmp_92;
  long unsigned int _93;
  const uint8_t[1] * _94;
  long int _95;
  sizetype _96;
  sizetype _97;
  const uint8_t * _98;
  short unsigned int _99;
  int _100;
  short unsigned int _101;
  sizetype _103;
  long unsigned int _105;
  const struct Vector * iftmp.41_106;
  long unsigned int _108;
  long int _109;
  sizetype _110;
  sizetype _111;
  const uint8_t * _112;
  short unsigned int _113;
  int _114;
  short unsigned int _115;
  sizetype _117;
  long unsigned int _119;
  const struct Vector * iftmp.41_120;
  long unsigned int _127;
  const uint8_t * _128;
  long unsigned int _129;
  long unsigned int _131;
  const struct SubGraph * _132;
  long int _134;
  sizetype _135;
  sizetype _136;
  const uint8_t * _137;
  short unsigned int _138;
  int _139;
  short unsigned int _140;
  long unsigned int _141;
  sizetype _142;
  long unsigned int _144;
  const struct Vector * iftmp.55_145;
  int _148;
  unsigned int _166;
  unsigned int tensor_index.61_167;
  const uint8_t[1] * _170;
  long int _171;
  sizetype _172;
  sizetype _173;
  const uint8_t * _174;
  short unsigned int _175;
  int _176;
  short unsigned int _177;
  long int _178;
  sizetype _179;
  long unsigned int _181;
  const struct String * iftmp.56_182;
  const struct String * iftmp.56_183;
  const uint8_t * _184;
  int _185;
  short unsigned int _192;
  long unsigned int _193;
  sizetype _194;
  long unsigned int _196;
  const struct Vector * iftmp.42_197;
  short unsigned int _198;
  sizetype _200;
  const void * _201;
  long unsigned int _202;
  bool _203;
  long unsigned int iftmp.1_204;
  const uint8_t[1] * _206;
  long int _207;
  sizetype _208;
  sizetype _209;
  const uint8_t * _210;
  short unsigned int _211;
  int _212;
  short unsigned int _213;
  long int cstore_214;
  sizetype _215;
  long unsigned int _217;
  const struct Vector * iftmp.3_218;
  const long int * _219;
  const uint32_t * _221;
  bool _224;
  const uint8_t * _227;
  long unsigned int _228;
  long unsigned int _230;
  const struct Metadata * _231;
  long unsigned int _232;
  const uint8_t * _233;
  long unsigned int _234;
  long unsigned int _236;
  const struct Buffer * _237;
  const uint8_t * _239;
  unsigned int _241;
  unsigned int _243;
  struct TfLiteEvalTensor * _244;
  void * * _245;
  size_t * _246;
  TfLiteStatus _247;
  void * _248;
  long int _250;
  sizetype _251;
  sizetype _252;
  const uint8_t * _253;
  short unsigned int _254;
  int _255;
  short unsigned int _256;
  bool _257;
  sizetype _258;
  long unsigned int _260;
  const struct Vector * iftmp.41_261;
  long unsigned int _263;
  const uint8_t[1] * _264;
  long int _265;
  sizetype _266;
  sizetype _267;
  const uint8_t * _268;
  short unsigned int _269;
  int _270;
  short unsigned int _271;
  sizetype _273;
  const void * _274;
  unsigned char _275;
  bool iftmp.57_277;
  unsigned int _278;
  const int32_t * _279;
  long int _280;
  short unsigned int _289;
  bool _290;
  sizetype _291;
  long unsigned int _293;
  const struct Vector * iftmp.13_294;
  long unsigned int _296;
  const uint8_t * _306;
  long unsigned int _307;
  const long int * _308;
  long int _309;
  unsigned int tensor_index.59_311;
  unsigned int _312;
  short unsigned int _315;
  const struct Vector * iftmp.13_316;
  sizetype _317;
  long unsigned int _319;
  const struct Vector * iftmp.13_320;
  long unsigned int _321;
  long unsigned int _322;
  unsigned int prephitmp_329;
  short unsigned int _340;
  bool _341;
  sizetype _342;
  long unsigned int _344;
  const struct Vector * iftmp.31_345;
  long unsigned int _347;
  long unsigned int _348;
  int _349;
  short unsigned int _351;
  sizetype _352;
  sizetype _353;
  long unsigned int _355;
  const struct Vector * iftmp.31_356;
  short unsigned int _357;
  long unsigned int _358;
  long unsigned int _359;
  long unsigned int _361;
  long unsigned int i.62_374;
  short unsigned int _384;
  sizetype _386;
  long unsigned int _388;
  const struct Vector * iftmp.13_389;
  long unsigned int _391;
  const uint8_t * _401;
  long unsigned int _402;
  const long int * _403;
  long int _404;
  unsigned int tensor_index.64_406;
  unsigned int _407;
  int _409;
  short unsigned int _411;
  sizetype _413;
  long unsigned int _415;
  const struct Vector * iftmp.13_416;
  long unsigned int _418;
  const uint8_t * _428;
  long unsigned int _429;
  const long int * _430;
  long int _431;
  unsigned int tensor_index.66_433;
  unsigned int _434;
  int _436;
  long unsigned int _444;
  const uint8_t * _445;
  long unsigned int _446;
  long unsigned int _448;
  const struct Tensor * _449;
  const uint8_t * _451;
  long unsigned int _452;
  long unsigned int _454;
  const struct Operator * _455;
  unsigned int _460;
  unsigned int _461;
  unsigned int _463;
  unsigned int _466;
  uint8_t * * _468;
  unsigned int _469;
  int _470;
  struct SimpleMemoryAllocator * _472;
  uint8_t * _473;
  struct ScratchBufferRequest * _474;
  unsigned int _476;
  bool _478;
  unsigned int _479;
  unsigned int _480;
  long int _481;
  int aligned_bytes_required.67_484;
  int _485;
  int _486;
  TfLiteStatus _487;
  int aligned_bytes_required.67_488;
  int _489;
  int _490;
  TfLiteStatus _491;
  unsigned int _495;
  bool _497;
  TfLiteStatus _501;
  void * * _502;
  int offset.68_503;
  sizetype offset.69_504;
  uint8_t * _505;
  long unsigned int _512;
  const uint8_t[1] * prephitmp_514;
  unsigned int _544;
  sizetype _547;
  const uint8_t[1] * _549;
  long unsigned int _552;
  bool _581;
  long unsigned int _582;
  long unsigned int _655;
  long unsigned int _661;
  long unsigned int _666;
  int prephitmp_670;
  int _685;
  long unsigned int _690;
  short unsigned int pretmp_691;
  const uint8_t[1] * _692;
  sizetype _693;
  sizetype _694;
  TfLiteStatus _695;
  TfLiteStatus _696;
  TfLiteStatus _698;
  long unsigned int _699;
  const struct Vector * iftmp.42_702;
  TfLiteStatus _704;
  const uint8_t * _714;
  long unsigned int _715;
  const long int * _716;
  long int _717;
  unsigned int tensor_index.61_718;
  unsigned int _719;
  sizetype _724;
  bool _730;
  bool prephitmp_731;
  short unsigned int pretmp_734;
  const struct Vector * iftmp.42_736;
  const struct Vector * iftmp.42_737;
  long int pretmp_738;
  long int pretmp_745;

  <bb 2>:
  _26 = &MEM[(const struct Table *)model_8(D)].data_;
  _25 = MEM[(const long int *)model_8(D)];
  _15 = (sizetype) _25;
  _14 = -_15;
  _9 = _26 + _14;
  _84 = MEM[(const short unsigned int *)_9];
  _85 = (int) _84;
  if (_85 > 8)
    goto <bb 3>;
  else
    goto <bb 149>;

  <bb 3>:
  _86 = MEM[(const short unsigned int *)_9 + 8B];
  _88 = (sizetype) _86;
  p_89 = _26 + _88;
  if (_86 != 0)
    goto <bb 4>;
  else
    goto <bb 149>;

  <bb 4>:
  _90 = MEM[(const long unsigned int *)p_89];
  iftmp.27_91 = p_89 + _90;
  subgraph_idx.48_11 = (long unsigned int) subgraph_idx_10(D);
  _127 = iftmp.27_91->length_;
  if (subgraph_idx.48_11 < _127)
    goto <bb 6>;
  else
    goto <bb 5>;

  <bb 5>:
  __assert_func ("C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h", 262, &__PRETTY_FUNCTION__, "i < size()");

  <bb 6>:
  _128 = &MEM[(void *)iftmp.27_91 + 4B];
  _129 = subgraph_idx.48_11 * 4;
  p_130 = _128 + _129;
  _131 = MEM[(const long unsigned int *)p_130];
  _132 = p_130 + _131;
  _94 = &MEM[(const struct Table *)_132].data_;
  _95 = MEM[(const long int *)_132];
  _96 = (sizetype) _95;
  _97 = -_96;
  _98 = _94 + _97;
  _99 = MEM[(const short unsigned int *)_98];
  _100 = (int) _99;
  if (_100 > 4)
    goto <bb 7>;
  else
    goto <bb 150>;

  <bb 7>:
  _101 = MEM[(const short unsigned int *)_98 + 4B];
  _103 = (sizetype) _101;
  p_104 = _94 + _103;
  if (_101 != 0)
    goto <bb 8>;
  else
    goto <bb 150>;

  <bb 8>:
  _105 = MEM[(const long unsigned int *)p_104];
  iftmp.41_106 = p_104 + _105;
  _93 = iftmp.41_106->length_;
  _17 = this_16(D)->scratch_buffer_request_count_;
  allocation_info_count_18 = _17 + _93;
  bytes_19 = allocation_info_count_18 * 24;
  _20 = this_16(D)->memory_allocator_;
  _21 = _20->_vptr.SimpleMemoryAllocator;
  _22 = MEM[(int (*__vtbl_ptr_type) () *)_21 + 16B];
  _24 = OBJ_TYPE_REF(_22;(struct SimpleMemoryAllocator)_20->4) (_20, bytes_19, 4);
  if (_24 == 0B)
    goto <bb 9>;
  else
    goto <bb 10>;

  <bb 9>:
  goto <bb 139>;

  <bb 10>:
  _109 = MEM[(const long int *)_132];
  _110 = (sizetype) _109;
  _111 = -_110;
  _112 = _94 + _111;
  _113 = MEM[(const short unsigned int *)_112];
  _114 = (int) _113;
  if (_114 > 4)
    goto <bb 11>;
  else
    goto <bb 151>;

  <bb 11>:
  _115 = MEM[(const short unsigned int *)_112 + 4B];
  _117 = (sizetype) _115;
  p_118 = _94 + _117;
  if (_115 != 0)
    goto <bb 12>;
  else
    goto <bb 151>;

  <bb 12>:
  _119 = MEM[(const long unsigned int *)p_118];
  iftmp.41_120 = p_118 + _119;
  _108 = iftmp.41_120->length_;
  _27 = this_16(D)->scratch_buffer_request_count_;
  MEM[(struct  &)&builder] ={v} {CLOBBER};
  _134 = MEM[(const long int *)model_8(D)];
  _135 = (sizetype) _134;
  _136 = -_135;
  _137 = _26 + _136;
  _138 = MEM[(const short unsigned int *)_137];
  _139 = (int) _138;
  if (_139 > 16)
    goto <bb 13>;
  else
    goto <bb 37>;

  <bb 13>:
  _140 = MEM[(const short unsigned int *)_137 + 16B];
  _142 = (sizetype) _140;
  p_143 = _26 + _142;
  if (_140 != 0)
    goto <bb 14>;
  else
    goto <bb 37>;

  <bb 14>:
  _144 = MEM[(const long unsigned int *)p_143];
  iftmp.55_145 = p_143 + _144;
  if (iftmp.55_145 != 0B)
    goto <bb 15>;
  else
    goto <bb 37>;

  <bb 15>:
  _87 = iftmp.55_145->length_;
  if (_87 != 0)
    goto <bb 16>;
  else
    goto <bb 37>;

  <bb 16>:

  <bb 17>:
  # i_735 = PHI <0(16), i_223(36)>
  # offline_planner_offsets_697 = PHI <0B(16), offline_planner_offsets_580(36)>
  if (_87 > i_735)
    goto <bb 19>;
  else
    goto <bb 18>;

  <bb 18>:
  __assert_func ("C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h", 262, &__PRETTY_FUNCTION__, "i < size()");

  <bb 19>:
  _227 = &MEM[(void *)iftmp.55_145 + 4B];
  _228 = i_735 * 4;
  p_229 = _227 + _228;
  _230 = MEM[(const long unsigned int *)p_229];
  _231 = p_229 + _230;
  _170 = &MEM[(const struct Table *)_231].data_;
  _171 = MEM[(const long int *)_231];
  _172 = (sizetype) _171;
  _173 = -_172;
  _174 = _170 + _173;
  _175 = MEM[(const short unsigned int *)_174];
  _176 = (int) _175;
  if (_176 > 4)
    goto <bb 20>;
  else
    goto <bb 22>;

  <bb 20>:
  _177 = MEM[(const short unsigned int *)_174 + 4B];
  _179 = (sizetype) _177;
  p_180 = _170 + _179;
  if (_177 != 0)
    goto <bb 21>;
  else
    goto <bb 22>;

  <bb 21>:
  _181 = MEM[(const long unsigned int *)p_180];
  iftmp.56_182 = p_180 + _181;

  <bb 22>:
  # iftmp.56_183 = PHI <0B(20), iftmp.56_182(21), 0B(19)>
  _184 = &MEM[(void *)iftmp.56_183 + 4B];
  _185 = strncmp (_184, &kOfflineMemAllocMetadata, 23);
  if (_185 == 0)
    goto <bb 23>;
  else
    goto <bb 34>;

  <bb 23>:
  if (_139 > 12)
    goto <bb 24>;
  else
    goto <bb 26>;

  <bb 24>:
  _192 = MEM[(const short unsigned int *)_137 + 12B];
  _194 = (sizetype) _192;
  p_195 = _26 + _194;
  if (_192 != 0)
    goto <bb 25>;
  else
    goto <bb 142>;

  <bb 25>:
  _196 = MEM[(const long unsigned int *)p_195];
  iftmp.42_197 = p_195 + _196;
  goto <bb 142>;

  <bb 26>:
  if (_176 > 6)
    goto <bb 27>;
  else
    goto <bb 152>;

  <bb 27>:
  # iftmp.42_736 = PHI <0B(26), iftmp.42_702(142)>
  _198 = MEM[(const short unsigned int *)_174 + 6B];
  if (_198 != 0)
    goto <bb 28>;
  else
    goto <bb 29>;

  <bb 28>:
  _200 = (sizetype) _198;
  _201 = _170 + _200;
  _202 = MEM[(const long unsigned int *)_201];

  <bb 29>:
  # iftmp.1_204 = PHI <0(27), _202(28), 0(142)>
  # iftmp.42_737 = PHI <iftmp.42_736(27), iftmp.42_736(28), iftmp.42_702(142)>
  _232 = iftmp.42_737->length_;
  if (iftmp.1_204 < _232)
    goto <bb 31>;
  else
    goto <bb 30>;

  <bb 30>:
  __assert_func ("C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h", 262, &__PRETTY_FUNCTION__, "i < size()");

  <bb 31>:
  _233 = &MEM[(void *)iftmp.42_737 + 4B];
  _234 = iftmp.1_204 * 4;
  p_235 = _233 + _234;
  _236 = MEM[(const long unsigned int *)p_235];
  _237 = p_235 + _236;
  _206 = &MEM[(const struct Table *)_237].data_;
  _207 = MEM[(const long int *)_237];
  _208 = (sizetype) _207;
  _209 = -_208;
  _210 = _206 + _209;
  _211 = MEM[(const short unsigned int *)_210];
  _212 = (int) _211;
  if (_212 > 4)
    goto <bb 32>;
  else
    goto <bb 153>;

  <bb 32>:
  _213 = MEM[(const short unsigned int *)_210 + 4B];
  _215 = (sizetype) _213;
  p_216 = _206 + _215;
  if (_213 != 0)
    goto <bb 33>;
  else
    goto <bb 153>;

  <bb 33>:
  _217 = MEM[(const long unsigned int *)p_216];
  iftmp.3_218 = p_216 + _217;
  nbr_tensors_220 = MEM[(const uint32_t *)iftmp.3_218 + 12B];
  _221 = &MEM[(void *)iftmp.3_218 + 16B];
  if (_108 != nbr_tensors_220)
    goto <bb 9>;
  else
    goto <bb 34>;

  <bb 34>:
  # offline_planner_offsets_580 = PHI <offline_planner_offsets_697(22), _221(33)>
  i_223 = i_735 + 1;
  if (_87 > i_223)
    goto <bb 36>;
  else
    goto <bb 35>;

  <bb 35>:
  # offline_planner_offsets_689 = PHI <offline_planner_offsets_580(34)>
  goto <bb 37>;

  <bb 36>:
  goto <bb 17>;

  <bb 37>:
  # offline_planner_offsets_747 = PHI <0B(13), offline_planner_offsets_689(35), 0B(12), 0B(15), 0B(14)>
  if (eval_tensors_33(D) != 0B)
    goto <bb 38>;
  else
    goto <bb 39>;

  <bb 38>:
  if (_108 == 0)
    goto <bb 40>;
  else
    goto <bb 42>;

  <bb 39>:
  abort ();

  <bb 40>:
  # prephitmp_514 = PHI <_549(58), _112(38)>
  # prephitmp_670 = PHI <_148(58), _114(38)>
  if (prephitmp_670 > 6)
    goto <bb 59>;
  else
    goto <bb 41>;

  <bb 41>:
  goto <bb 155>;

  <bb 42>:

  <bb 43>:
  # i_733 = PHI <0(42), i_281(57)>
  _241 = i_733 * 24;
  current_242 = _24 + _241;
  _243 = i_733 * 12;
  _244 = eval_tensors_33(D) + _243;
  _245 = &_244->data.data;
  current_242->output_ptr = _245;
  _246 = &current_242->bytes;
  _247 = tflite::TfLiteEvalTensorByteLength (_244, _246);
  if (_247 != 0)
    goto <bb 44>;
  else
    goto <bb 45>;

  <bb 44>:
  # _704 = PHI <_247(43)>
  goto <bb 139>;

  <bb 45>:
  current_242->first_created = -1;
  current_242->last_used = -1;
  _248 = _244->data.data;
  if (_248 == 0B)
    goto <bb 46>;
  else
    goto <bb 54>;

  <bb 46>:
  _250 = MEM[(const long int *)_132];
  _251 = (sizetype) _250;
  _252 = -_251;
  _253 = _94 + _252;
  _254 = MEM[(const short unsigned int *)_253];
  _255 = (int) _254;
  if (_255 > 4)
    goto <bb 47>;
  else
    goto <bb 154>;

  <bb 47>:
  _256 = MEM[(const short unsigned int *)_253 + 4B];
  _258 = (sizetype) _256;
  p_259 = _94 + _258;
  if (_256 != 0)
    goto <bb 48>;
  else
    goto <bb 154>;

  <bb 48>:
  _260 = MEM[(const long unsigned int *)p_259];
  iftmp.41_261 = p_259 + _260;
  _444 = iftmp.41_261->length_;
  if (_444 > i_733)
    goto <bb 50>;
  else
    goto <bb 49>;

  <bb 49>:
  __assert_func ("C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h", 262, &__PRETTY_FUNCTION__, "i < size()");

  <bb 50>:
  _445 = &MEM[(void *)iftmp.41_261 + 4B];
  _446 = i_733 * 4;
  p_447 = _445 + _446;
  _448 = MEM[(const long unsigned int *)p_447];
  _449 = p_447 + _448;
  _264 = &MEM[(const struct Table *)_449].data_;
  _265 = MEM[(const long int *)_449];
  _266 = (sizetype) _265;
  _267 = -_266;
  _268 = _264 + _267;
  _269 = MEM[(const short unsigned int *)_268];
  _270 = (int) _269;
  if (_270 > 14)
    goto <bb 51>;
  else
    goto <bb 53>;

  <bb 51>:
  _271 = MEM[(const short unsigned int *)_268 + 14B];
  if (_271 != 0)
    goto <bb 52>;
  else
    goto <bb 54>;

  <bb 52>:
  _273 = (sizetype) _271;
  _274 = _264 + _273;
  _275 = MEM[(const unsigned char *)_274];
  _730 = _275 == 0;

  <bb 53>:
  # prephitmp_731 = PHI <1(50), _730(52)>

  <bb 54>:
  # iftmp.57_277 = PHI <0(45), prephitmp_731(53), 1(51)>
  current_242->needs_allocating = iftmp.57_277;
  if (offline_planner_offsets_747 != 0B)
    goto <bb 55>;
  else
    goto <bb 56>;

  <bb 55>:
  _278 = i_733 * 4;
  _279 = offline_planner_offsets_747 + _278;
  _280 = *_279;

  <bb 56>:
  # cstore_214 = PHI <_280(55), -1(54)>
  current_242->offline_offset = cstore_214;
  i_281 = i_733 + 1;
  if (_108 <= i_281)
    goto <bb 58>;
  else
    goto <bb 57>;

  <bb 57>:
  goto <bb 43>;

  <bb 58>:
  pretmp_738 = MEM[(const long int *)_132];
  _547 = (sizetype) pretmp_738;
  _724 = -_547;
  _549 = _94 + _724;
  pretmp_734 = MEM[(const short unsigned int *)_549];
  _148 = (int) pretmp_734;
  goto <bb 40>;

  <bb 59>:

  <bb 60>:
  # i_297 = PHI <0(59), i_314(64)>
  _289 = MEM[(const short unsigned int *)prephitmp_514 + 6B];
  _291 = (sizetype) _289;
  p_292 = _94 + _291;
  if (_289 != 0)
    goto <bb 61>;
  else
    goto <bb 155>;

  <bb 61>:
  _293 = MEM[(const long unsigned int *)p_292];
  iftmp.13_294 = p_292 + _293;
  _296 = iftmp.13_294->length_;
  if (_296 > i_297)
    goto <bb 64>;
  else
    goto <bb 62>;

  <bb 62>:
  if (prephitmp_670 > 8)
    goto <bb 65>;
  else
    goto <bb 63>;

  <bb 63>:
  goto <bb 156>;

  <bb 64>:
  _306 = &MEM[(void *)iftmp.13_294 + 4B];
  _307 = i_297 * 4;
  _308 = _306 + _307;
  _309 = *_308;
  tensor_index.59_311 = (unsigned int) _309;
  _312 = tensor_index.59_311 * 24;
  current_313 = _24 + _312;
  current_313->first_created = 0;
  i_314 = i_297 + 1;
  goto <bb 60>;

  <bb 65>:
  if (prephitmp_670 > 10)
    goto <bb 69>;
  else
    goto <bb 66>;

  <bb 66>:
  _357 = MEM[(const short unsigned int *)prephitmp_514 + 8B];
  _352 = (sizetype) _357;
  p_346 = _94 + _352;
  if (_357 != 0)
    goto <bb 67>;
  else
    goto <bb 156>;

  <bb 67>:
  _321 = MEM[(const long unsigned int *)p_346];
  iftmp.13_316 = p_346 + _321;
  _263 = iftmp.13_316->length_;
  if (_263 != 0)
    goto <bb 68>;
  else
    goto <bb 73>;

  <bb 68>:
  _239 = &MEM[(void *)iftmp.13_316 + 4B];
  _219 = _239;
  _178 = *_219;
  tensor_index.61_167 = (unsigned int) _178;
  _166 = tensor_index.61_167 * 24;
  current_165 = _24 + _166;
  goto <bb 157>;

  <bb 69>:

  <bb 70>:
  # i_323 = PHI <0(69), i_350(72)>
  _315 = MEM[(const short unsigned int *)prephitmp_514 + 8B];
  _317 = (sizetype) _315;
  p_318 = _94 + _317;
  if (_315 != 0)
    goto <bb 71>;
  else
    goto <bb 156>;

  <bb 71>:
  _319 = MEM[(const long unsigned int *)p_318];
  iftmp.13_320 = p_318 + _319;
  _322 = iftmp.13_320->length_;
  if (_322 > i_323)
    goto <bb 143>;
  else
    goto <bb 73>;

  <bb 72>:
  _344 = MEM[(const long unsigned int *)p_343];
  iftmp.31_345 = p_343 + _344;
  _347 = iftmp.31_345->length_;
  _348 = _347 + 4294967295;
  _349 = (int) _348;
  current_720->last_used = _349;
  i_350 = i_323 + 1;
  goto <bb 70>;

  <bb 73>:
  if (prephitmp_670 > 10)
    goto <bb 74>;
  else
    goto <bb 158>;

  <bb 74>:
  _351 = MEM[(const short unsigned int *)prephitmp_514 + 10B];
  _353 = (sizetype) _351;
  p_354 = _94 + _353;
  if (_351 != 0)
    goto <bb 75>;
  else
    goto <bb 158>;

  <bb 75>:
  _355 = MEM[(const long unsigned int *)p_354];
  iftmp.31_356 = p_354 + _355;
  _358 = iftmp.31_356->length_;
  _359 = _358 + 4294967295;
  i_360 = (int) _359;
  if (i_360 < 0)
    goto <bb 144>;
  else
    goto <bb 76>;

  <bb 76>:

  <bb 77>:
  # i_732 = PHI <i_360(76), i_438(96)>
  i.62_374 = (long unsigned int) i_732;
  if (_358 > i.62_374)
    goto <bb 79>;
  else
    goto <bb 78>;

  <bb 78>:
  __assert_func ("C:/Renesas/e2studio_2021_01_workspace_RZA2M_ANPR/ANPR_RZA2M_GR_MANGO/src/tensorflow_lite/third_party/flatbuffers/include/flatbuffers/flatbuffers.h", 262, &__PRETTY_FUNCTION__, "i < size()");

  <bb 79>:
  _451 = &MEM[(void *)iftmp.31_356 + 4B];
  _452 = i.62_374 * 4;
  p_453 = _451 + _452;
  _454 = MEM[(const long unsigned int *)p_453];
  _455 = p_453 + _454;
  pretmp_92 = &MEM[(const struct Table *)_455].data_;
  pretmp_745 = MEM[(const long int *)_455];
  _694 = (sizetype) pretmp_745;
  _693 = -_694;
  _692 = pretmp_92 + _693;
  pretmp_691 = MEM[(const short unsigned int *)_692];
  _685 = (int) pretmp_691;
  if (_685 > 6)
    goto <bb 81>;
  else
    goto <bb 80>;

  <bb 80>:
  goto <bb 159>;

  <bb 81>:

  <bb 82>:
  # n_392 = PHI <0(81), n_410(88)>
  _384 = MEM[(const short unsigned int *)_692 + 6B];
  _386 = (sizetype) _384;
  p_387 = pretmp_92 + _386;
  if (_384 != 0)
    goto <bb 83>;
  else
    goto <bb 159>;

  <bb 83>:
  _388 = MEM[(const long unsigned int *)p_387];
  iftmp.13_389 = p_387 + _388;
  _391 = iftmp.13_389->length_;
  if (_391 > n_392)
    goto <bb 86>;
  else
    goto <bb 84>;

  <bb 84>:
  if (_685 > 8)
    goto <bb 89>;
  else
    goto <bb 85>;

  <bb 85>:
  goto <bb 160>;

  <bb 86>:
  _401 = &MEM[(void *)iftmp.13_389 + 4B];
  _402 = n_392 * 4;
  _403 = _401 + _402;
  _404 = *_403;
  tensor_index.64_406 = (unsigned int) _404;
  _407 = tensor_index.64_406 * 24;
  current_408 = _24 + _407;
  _409 = current_408->last_used;
  _290 = _409 < i_732;
  _257 = _409 == -1;
  _203 = _257 | _290;
  if (_203 != 0)
    goto <bb 87>;
  else
    goto <bb 88>;

  <bb 87>:
  current_408->last_used = i_732;

  <bb 88>:
  n_410 = n_392 + 1;
  goto <bb 82>;

  <bb 89>:

  <bb 90>:
  # n_419 = PHI <0(89), n_437(94)>
  _411 = MEM[(const short unsigned int *)_692 + 8B];
  _413 = (sizetype) _411;
  p_414 = pretmp_92 + _413;
  if (_411 != 0)
    goto <bb 91>;
  else
    goto <bb 160>;

  <bb 91>:
  _415 = MEM[(const long unsigned int *)p_414];
  iftmp.13_416 = p_414 + _415;
  _418 = iftmp.13_416->length_;
  if (_418 > n_419)
    goto <bb 92>;
  else
    goto <bb 95>;

  <bb 92>:
  _428 = &MEM[(void *)iftmp.13_416 + 4B];
  _429 = n_419 * 4;
  _430 = _428 + _429;
  _431 = *_430;
  tensor_index.66_433 = (unsigned int) _431;
  _434 = tensor_index.66_433 * 24;
  current_435 = _24 + _434;
  _436 = current_435->first_created;
  _224 = _436 > i_732;
  _581 = _436 == -1;
  _341 = _224 | _581;
  if (_341 != 0)
    goto <bb 93>;
  else
    goto <bb 94>;

  <bb 93>:
  current_435->first_created = i_732;

  <bb 94>:
  n_437 = n_419 + 1;
  goto <bb 90>;

  <bb 95>:
  i_438 = i_732 + -1;
  if (i_438 < 0)
    goto <bb 144>;
  else
    goto <bb 96>;

  <bb 96>:
  goto <bb 77>;

  <bb 97>:

  <bb 98>:
  # i_729 = PHI <_108(97), i_471(99)>
  _460 = i_729 - _108;
  _461 = _460 * 8;
  current_request_462 = _474 + _461;
  _463 = _460 * 4;
  current_handle_464 = scratch_buffer_handles_38(D) + _463;
  _466 = i_729 * 24;
  current_467 = _24 + _466;
  _468 = &current_handle_464->data;
  current_467->output_ptr = _468;
  _469 = current_request_462->bytes;
  current_467->bytes = _469;
  _470 = current_request_462->node_idx;
  current_467->first_created = _470;
  current_467->last_used = _470;
  current_467->offline_offset = -1;
  current_467->needs_allocating = 1;
  i_471 = i_729 + 1;
  if (i_471 >= _544)
    goto <bb 100>;
  else
    goto <bb 99>;

  <bb 99>:
  goto <bb 98>;

  <bb 100>:

  <bb 101>:
  _41 = this_16(D)->memory_allocator_;
  _43 = tflite::SimpleMemoryAllocator::GetAvailableMemory (_41, 16);
  _44 = this_16(D)->memory_allocator_;
  _45 = _44->_vptr.SimpleMemoryAllocator;
  _46 = MEM[(int (*__vtbl_ptr_type) () *)_45 + 16B];
  _48 = OBJ_TYPE_REF(_46;(struct SimpleMemoryAllocator)_44->4) (_44, _43, 16);
  if (_48 == 0B)
    goto <bb 9>;
  else
    goto <bb 102>;

  <bb 102>:
  remaining_arena_size.50_49 = (int) _43;
  tflite::GreedyMemoryPlanner::GreedyMemoryPlanner (&planner, _48, remaining_arena_size.50_49);
  _51 = this_16(D)->error_reporter_;
  if (allocation_info_count_18 == 0)
    goto <bb 145>;
  else
    goto <bb 103>;

  <bb 103>:

  <bb 104>:
  # i_728 = PHI <0(103), i_492(106)>
  _476 = i_728 * 24;
  current_477 = _24 + _476;
  _478 = current_477->needs_allocating;
  if (_478 != 0)
    goto <bb 107>;
  else
    goto <bb 105>;

  <bb 105>:
  i_492 = i_728 + 1;
  if (allocation_info_count_18 <= i_492)
    goto <bb 145>;
  else
    goto <bb 106>;

  <bb 106>:
  goto <bb 104>;

  <bb 107>:
  _479 = current_477->bytes;
  _480 = tflite::AlignSizeUp (_479, 16);

  <bb 108>:
  _481 = current_477->offline_offset;
  if (_481 == -1)
    goto <bb 109>;
  else
    goto <bb 112>;

  <bb 109>:
  aligned_bytes_required.67_484 = (int) _480;
  _485 = current_477->first_created;
  _486 = current_477->last_used;
  _487 = tflite::GreedyMemoryPlanner::AddBuffer (&planner, _51, aligned_bytes_required.67_484, _485, _486);
  goto <bb 111>;

<L27>:
  goto <bb 141> (<L24>);

  <bb 111>:
  if (_487 != 0)
    goto <bb 137>;
  else
    goto <bb 105>;

  <bb 112>:
  aligned_bytes_required.67_488 = (int) _480;
  _489 = current_477->first_created;
  _490 = current_477->last_used;
  _491 = tflite::GreedyMemoryPlanner::AddBuffer (&planner, _51, aligned_bytes_required.67_488, _489, _490, _481);
  goto <bb 114>;

<L28>:
  goto <bb 141> (<L24>);

  <bb 114>:
  if (_491 != 0)
    goto <bb 115>;
  else
    goto <bb 105>;

  <bb 115>:
  # _696 = PHI <_491(114)>
  goto <bb 138>;

  <bb 116>:
  _58 = this_16(D)->memory_allocator_;
  _60 = tflite::SimpleMemoryAllocator::GetAvailableMemory (_58, 16);
  goto <bb 118>;

<L29>:
  goto <bb 141> (<L24>);

  <bb 118>:
  _62 = tflite::GreedyMemoryPlanner::GetMaximumMemorySize (&planner);
  goto <bb 120>;

<L30>:
  goto <bb 141> (<L24>);

  <bb 120>:
  if (_60 < _62)
    goto <bb 138>;
  else
    goto <bb 121>;

  <bb 121>:
  _63 = this_16(D)->error_reporter_;
  _64 = this_16(D)->memory_allocator_;
  _66 = tflite::SimpleMemoryAllocator::GetHeadBuffer (_64);
  goto <bb 123>;

<L31>:
  goto <bb 141> (<L24>);

  <bb 123>:
  if (allocation_info_count_18 == 0)
    goto <bb 147>;
  else
    goto <bb 124>;

  <bb 124>:

  <bb 125>:
  # i_727 = PHI <0(124), i_507(132)>
  # planner_index_726 = PHI <0(124), planner_index_509(132)>
  _495 = i_727 * 24;
  current_496 = _24 + _495;
  _497 = current_496->needs_allocating;
  if (_497 != 0)
    goto <bb 126>;
  else
    goto <bb 131>;

  <bb 126>:
  offset = -1;
  _501 = tflite::GreedyMemoryPlanner::GetOffsetForBuffer (&planner.D.182041, _63, planner_index_726, &offset);
  goto <bb 128>;

<L32>:
  goto <bb 141> (<L24>);

  <bb 128>:
  if (_501 != 0)
    goto <bb 129>;
  else
    goto <bb 130>;

  <bb 129>:
  # _695 = PHI <_501(128)>
  offset ={v} {CLOBBER};
  goto <bb 138>;

  <bb 130>:
  _502 = current_496->output_ptr;
  offset.68_503 = offset;
  offset.69_504 = (sizetype) offset.68_503;
  _505 = _66 + offset.69_504;
  *_502 = _505;
  planner_index_506 = planner_index_726 + 1;
  offset ={v} {CLOBBER};

  <bb 131>:
  # planner_index_509 = PHI <planner_index_726(125), planner_index_506(130)>
  i_507 = i_727 + 1;
  if (allocation_info_count_18 <= i_507)
    goto <bb 147>;
  else
    goto <bb 132>;

  <bb 132>:
  goto <bb 125>;

  <bb 133>:
  _71 = this_16(D)->max_head_buffer_usage_;
  if (_70 > _71)
    goto <bb 134>;
  else
    goto <bb 135>;

  <bb 134>:
  this_16(D)->max_head_buffer_usage_ = _70;

  <bb 135>:
  # prephitmp_329 = PHI <_71(133), _70(134)>
  _73 = this_16(D)->memory_allocator_;
  _74 = _73->_vptr.SimpleMemoryAllocator;
  _75 = MEM[(int (*__vtbl_ptr_type) () *)_74 + 8B];
  _78 = OBJ_TYPE_REF(_75;(struct SimpleMemoryAllocator)_73->2) (_73, prephitmp_329, 16);
  goto <bb 138>;

<L33>:
  goto <bb 141> (<L24>);

  <bb 137>:
  # _698 = PHI <_487(111)>

  <bb 138>:
  # _1 = PHI <_698(137), 1(120), _695(129), _696(115), _78(135)>
  tflite::GreedyMemoryPlanner::~GreedyMemoryPlanner (&planner);

  <bb 139>:
  # _2 = PHI <1(9), _1(138), _704(44)>
  builder ={v} {CLOBBER};
  planner ={v} {CLOBBER};
  return _2;

<L26>:

<L24>:
  tflite::GreedyMemoryPlanner::~GreedyMemoryPlanner (&planner);
  resx 2

  <bb 142>:
  # iftmp.42_702 = PHI <iftmp.42_197(25), 0B(24)>
  if (_176 > 6)
    goto <bb 27>;
  else
    goto <bb 29>;

  <bb 143>:
  _714 = &MEM[(void *)iftmp.13_320 + 4B];
  _715 = i_323 * 4;
  _716 = _714 + _715;
  _717 = *_716;
  tensor_index.61_718 = (unsigned int) _717;
  _719 = tensor_index.61_718 * 24;
  current_720 = _24 + _719;
  _340 = MEM[(const short unsigned int *)prephitmp_514 + 10B];
  _342 = (sizetype) _340;
  p_343 = _94 + _342;
  if (_340 != 0)
    goto <bb 72>;
  else
    goto <bb 157>;

  <bb 144>:
  _472 = this_16(D)->memory_allocator_;
  _473 = tflite::SimpleMemoryAllocator::GetHeadBuffer (_472);
  _474 = tflite::AlignPointerUp (_473, 4);
  _544 = _27 + _108;
  if (_108 >= _544)
    goto <bb 101>;
  else
    goto <bb 97>;

  <bb 145>:
  _54 = this_16(D)->memory_allocator_;
  _55 = _54->_vptr.SimpleMemoryAllocator;
  _56 = MEM[(int (*__vtbl_ptr_type) () *)_55 + 20B];
  OBJ_TYPE_REF(_56;(struct SimpleMemoryAllocator)_54->5) (_54);
  goto <bb 116>;

<L34>:
  goto <bb 141> (<L24>);

  <bb 147>:
  _70 = tflite::GreedyMemoryPlanner::GetMaximumMemorySize (&planner);
  goto <bb 133>;

<L35>:
  goto <bb 141> (<L24>);

  <bb 149>:
  _361 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 150>:
  _193 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 151>:
  _141 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 152>:
  _582 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 153>:
  nbr_tensors_668 ={v} MEM[(const uint32_t *)0B + 12B];
  __builtin_trap ();

  <bb 154>:
  _552 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 155>:
  _512 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 156>:
  _661 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 157>:
  _655 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 158>:
  _690 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 159>:
  _699 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

  <bb 160>:
  _666 ={v} MEM[(const struct Vector *)0B].length_;
  __builtin_trap ();

}


